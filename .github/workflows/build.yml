name: Viral Video Automation

on:
  push:
    branches: [ "main" ]
  workflow_dispatch:

jobs:
  video-editor:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
    # 1. Setup Environment
    - name: Checkout repo
      uses: actions/checkout@v4

    - name: Set up Python 3.10
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'

    - name: Install System Deps (FFmpeg)
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg

    # 2. Install Python Libraries
    - name: Install Python Packages
      run: |
        pip install yt-dlp faster-whisper numpy openai tqdm torch

    # 3. Generate & Run Script
    - name: Run Video Editor
      run: |
        cat << 'EOF' > main.py
        import os, sys, subprocess, json, time, re
        from pathlib import Path

        print("=" * 60)
        print("VIRAL VIDEO EDITOR - GITHUB ACTIONS VERSION")
        print("=" * 60)

        import torch
        from openai import OpenAI
        from tqdm import tqdm
        import numpy as np

        # ----------------------------
        # CONFIGURATION
        # ----------------------------
        # URL VIDEO
        YOUTUBE_URL = "https://nsf-m4c-one-fr-03.sf-converter.com/prod-new/download/eyJtZWRpYUlkIjoiVEdFdi1IMkRZdUkiLCJ0aXRsZSI6Ik1vbWVuIEtldGlrYSBQdXRpbiBNZW51bWJhbmdrYW4gT3JhbmcgVGVya2F5YSBkaSBSdXNpYSBEYWxhbSBTZWtlamFwISIsImZvcm1hdCI6Im1wNCIsInF1YWxpdHkiOiI3MjAiLCJ0aW1lc3RhbXAiOjE3NjY5MjE1Mzh9.ea87b7c602174bd66e8876df674ceaf8"
        
        API_KEY = "Kontolondon" 
        API_BASE = "https://tes-coral.vercel.app/v1/"
        WHISPER_MODEL_NAME = "medium"

        # --- SETUP DIRECTORIES (Relative Paths) ---
        # Menggunakan current working directory (project root)
        BASE_DIR = Path.cwd()
        OUTPUT_DIR = BASE_DIR / "output"
        MODELS_DIR = BASE_DIR / "models"
        
        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
        MODELS_DIR.mkdir(parents=True, exist_ok=True)

        AUDIO_PATH = BASE_DIR / "audio.wav"
        VIDEO_PATH = BASE_DIR / "video.mp4"
        ZIP_OUTPUT_PATH = BASE_DIR / "viral_segments.zip"

        print(f"üìÇ Working Directory: {BASE_DIR}")
        print(f"üìÇ Output Directory: {OUTPUT_DIR}")

        # ----------------------------
        # INITIALIZE OPENAI CLIENT
        # ----------------------------
        try:
            openai_client = OpenAI(api_key=API_KEY, base_url=API_BASE)
            print("‚úÖ OpenAI client initialized")
        except Exception as e:
            print(f"‚ùå Failed to initialize OpenAI client: {e}")
            sys.exit(1)

        # ----------------------------
        # UTILITY FUNCTIONS
        # ----------------------------
        def download_youtube(url: str, output_path) -> Path:
            """Download video"""
            print(f"\nüì• DOWNLOADING VIDEO")
            clean_url = url.split('?')[0]
            try:
                cmd = [
                    "yt-dlp",
                    "-f", "best[height<=720][ext=mp4]/best[ext=mp4]/best",
                    "-o", str(output_path),
                    "--quiet", "--no-warnings",
                    clean_url
                ]
                subprocess.run(cmd, check=True, timeout=300)
                if output_path.exists():
                    print(f"   ‚úÖ Download successful: {output_path.name}")
                    return output_path
                raise FileNotFoundError("Video not found after download")
            except Exception as e:
                raise Exception(f"Download failed: {str(e)}")

        def convert_video_to_audio(video_path: Path, audio_path: Path) -> Path:
            """Convert to WAV"""
            print(f"\nüîÑ CONVERTING VIDEO TO AUDIO")
            cmd = [
                "ffmpeg", "-i", str(video_path), "-vn",
                "-acodec", "pcm_s16le", "-ar", "16000", "-ac", "1",
                "-y", str(audio_path)
            ]
            subprocess.run(cmd, check=True, stderr=subprocess.DEVNULL)
            print(f"   ‚úÖ Audio ready: {audio_path.name}")
            return audio_path

        def get_video_duration(path: Path) -> float:
            try:
                cmd = ["ffprobe", "-v", "error", "-show_entries", "format=duration", "-of", "default=noprint_wrappers=1:nokey=1", str(path)]
                return float(subprocess.check_output(cmd).decode().strip())
            except: return 0

        # ----------------------------
        # TRANSCRIPTION
        # ----------------------------
        class FasterWhisperTranscriber:
            def __init__(self, model_name):
                self.model_name = model_name
                self.model = None
            
            def load_model(self):
                print(f"\nüì• LOADING MODEL (Download to {MODELS_DIR})")
                from faster_whisper import WhisperModel
                self.model = WhisperModel(
                    self.model_name,
                    device="cpu", # GitHub Actions standard runner is CPU
                    compute_type="int8",
                    download_root=str(MODELS_DIR)
                )
                return self.model
            
            def transcribe(self, audio_path):
                if not self.model: self.load_model()
                print(f"\nüéôÔ∏è TRANSCRIBING...")
                segments_generator, info = self.model.transcribe(str(audio_path), beam_size=5)
                
                all_segments = []
                full_text = ""
                for segment in segments_generator:
                    all_segments.append({
                        "start": segment.start, "end": segment.end, "text": segment.text.strip()
                    })
                    full_text += segment.text.strip() + " "
                
                return {
                    "text": full_text.strip(),
                    "segments": all_segments,
                    "language": info.language
                }

        # ----------------------------
        # GPT-4 EDITOR
        # ----------------------------
        class GPT4VideoEditor:
            def __init__(self, client, video_path, transcript_data):
                self.client = client
                self.video_path = video_path
                self.transcript = transcript_data
                self.duration = get_video_duration(video_path)
            
            def analyze(self):
                print(f"\nüß† ANALYZING WITH GPT-4")
                segments = self.transcript.get("segments", [])
                transcript_text = ""
                for seg in segments[:50]:
                    transcript_text += f"[{seg['start']:.1f}s - {seg['end']:.1f}s]: {seg['text']}\\n"
                
                system_prompt = "You are a viral video editor. Create segments UNDER 60 SECONDS based on the transcript. Return ONLY a JSON array with objects containing: start_time, end_time, title, hook, target_platform."
                user_prompt = f"Video Duration: {self.duration}s. Analyze this transcript and find viral moments. Transcript:\\n{transcript_text}\\n\\nReturn JSON array only."

                try:
                    response = self.client.chat.completions.create(
                        model="gpt-4",
                        messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
                        temperature=0.7
                    )
                    return response.choices[0].message.content.strip()
                except Exception as e:
                    print(f"‚ùå GPT Error: {e}")
                    return None

            def parse(self, gpt_response):
                try:
                    # Simple JSON extraction
                    match = re.search(r'\[.*\]', gpt_response.strip(), re.DOTALL)
                    if not match: return []
                    data = json.loads(match.group(0))
                    
                    valid = []
                    for i, item in enumerate(data, 1):
                        start, end = float(item['start_time']), float(item['end_time'])
                        if (end - start) > 60: end = start + 60 # Force max 60s
                        item['index'] = i
                        item['start_time'] = start
                        item['end_time'] = end
                        item['duration'] = end - start
                        valid.append(item)
                    return valid
                except Exception as e:
                    print(f"‚ùå Parse Error: {e}")
                    return []

        # ----------------------------
        # CUTTER
        # ----------------------------
        def cut_video(video_path, segments, output_dir):
            print(f"\n‚úÇÔ∏è CUTTING {len(segments)} SEGMENTS")
            results = []
            for seg in segments:
                safe_title = re.sub(r'[^\w\s-]', '', seg['title']).strip().replace(" ", "_")[:30]
                out_name = output_dir / f"seg_{seg['index']:02d}_{safe_title}.mp4"
                
                cmd = [
                    "ffmpeg", "-y", "-i", str(video_path),
                    "-ss", str(seg['start_time']), "-to", str(seg['end_time']),
                    "-c:v", "libx264", "-c:a", "aac",
                    "-vf", "scale=1080:1920:force_original_aspect_ratio=decrease,pad=1080:1920:(ow-iw)/2:(oh-ih)/2:color=black",
                    str(out_name)
                ]
                subprocess.run(cmd, check=False, stderr=subprocess.DEVNULL)
                if out_name.exists():
                    print(f"   ‚úÖ Saved: {out_name.name}")
                    results.append(out_name)
            return results

        # ----------------------------
        # MAIN
        # ----------------------------
        def main():
            # 1. Download
            if not VIDEO_PATH.exists():
                download_youtube(YOUTUBE_URL, VIDEO_PATH)
            
            # 2. Audio
            convert_video_to_audio(VIDEO_PATH, AUDIO_PATH)
            
            # 3. Transcribe
            transcriber = FasterWhisperTranscriber(WHISPER_MODEL_NAME)
            res = transcriber.transcribe(AUDIO_PATH)
            
            # 4. Analyze
            editor = GPT4VideoEditor(openai_client, VIDEO_PATH, res)
            gpt_res = editor.analyze()
            if not gpt_res: return
            
            segments = editor.parse(gpt_res)
            print(f"   found {len(segments)} valid segments")

            # 5. Cut
            files = cut_video(VIDEO_PATH, segments, OUTPUT_DIR)
            
            # 6. Zip
            if files:
                import zipfile
                print(f"\nüì¶ Zipping results to {ZIP_OUTPUT_PATH}...")
                with zipfile.ZipFile(ZIP_OUTPUT_PATH, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    for f in files:
                        zipf.write(f, f.name)
                print("‚úÖ Zip created successfully")

        if __name__ == "__main__":
            main()
        EOF
        
        # Jalankan Script
        python main.py

    # 4. Upload Hasil Output (Zip File)
    - name: Upload Viral Segments Zip
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: viral-video-results
        path: viral_segments.zip
        retention-days: 5
