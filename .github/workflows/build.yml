name: ðŸš€ AI Shorts Generator - Full Auto

on:
  workflow_dispatch:
    inputs:
      video_url:
        description: 'URL video (YouTube/MP4)'
        required: true
        default: 'https://api.vidssave.com/api/contentsite_api/media/download_redirect?request=sgRpmKL3iNBpyIDr4IgGHBXJiSxcf0EYQuGexs_6KdEalT5ycrs3ffyBEZXevrdUBcrNn6iDw8MfLNTFhlNy7biCIOWf4sDWWBA_S3Gc0ACg1ZPIBzwNN6iyUU-0-PuEErnV6vklMuUiHCyNARF0XK'

jobs:
  generate-shorts:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
      - name: ðŸ“¥ Checkout code
        uses: actions/checkout@v4

      - name: ðŸ Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: âš™ï¸ Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg
          
          pip install --upgrade pip
          pip install yt-dlp moviepy openai-whisper
          pip install pillow numpy openai tiktoken

      - name: ðŸ¤– Create AI script
        run: |
          cat > generate_shorts.py << 'EOF'
#!/usr/bin/env python3
"""
AI Shorts Generator - Full Auto
AI menentukan semuanya: jumlah klip, durasi, kreativitas, dan resolusi
"""

import os
import sys
import json
import subprocess
import random
from pathlib import Path
from datetime import datetime

# ========== CONFIG ==========
API_KEY = "Kontolondon"
API_BASE = "https://tes-coral.vercel.app/v1/"
MODEL = "gpt-4"

# Setup directories
BASE_DIR = Path.cwd()
VIDEO_DIR = BASE_DIR / "videos"
OUTPUT_DIR = BASE_DIR / "shorts"
VIDEO_DIR.mkdir(exist_ok=True)
OUTPUT_DIR.mkdir(exist_ok=True)

# Get video URL from environment
VIDEO_URL = os.environ.get("VIDEO_URL", "")

class AIShortsGenerator:
    def __init__(self):
        self.video_path = VIDEO_DIR / "source.mp4"
        self.stats = {
            "start_time": datetime.now().isoformat(),
            "decisions": {},
            "results": []
        }
    
    def log(self, message):
        print(f"[{datetime.now().strftime('%H:%M:%S')}] {message}")
    
    def download_video(self):
        """Download video from URL"""
        self.log(f"Downloading video from: {VIDEO_URL[:80]}...")
        
        # Try yt-dlp first
        try:
            cmd = [
                'yt-dlp', '-f', 'best[height<=720]',
                '-o', str(self.video_path),
                '--quiet',
                VIDEO_URL
            ]
            subprocess.run(cmd, check=True, capture_output=True)
        except:
            # Fallback to curl
            self.log("yt-dlp failed, trying curl...")
            cmd = ['curl', '-L', '-o', str(self.video_path), VIDEO_URL]
            subprocess.run(cmd, capture_output=True)
        
        if self.video_path.exists():
            size_mb = self.video_path.stat().st_size / (1024 * 1024)
            self.log(f"âœ“ Video downloaded: {size_mb:.1f} MB")
            return True
        
        self.log("âœ— Failed to download video")
        return False
    
    def get_video_info(self):
        """Get basic video information"""
        try:
            import moviepy.editor as mp
            with mp.VideoFileClip(str(self.video_path)) as clip:
                return {
                    "duration": clip.duration,
                    "width": clip.w,
                    "height": clip.h,
                    "fps": clip.fps
                }
        except Exception as e:
            self.log(f"Error getting video info: {e}")
            return {"duration": 0, "width": 0, "height": 0}
    
    def transcribe_video(self):
        """Transcribe video using Whisper"""
        self.log("Transcribing audio with Whisper...")
        
        try:
            import whisper
            model = whisper.load_model("medium")
            result = model.transcribe(str(self.video_path), verbose=False)
            
            # Format transcript for AI
            segments = result.get("segments", [])
            transcript_lines = []
            
            for seg in segments[:100]:  # First 100 segments max
                start = seg.get("start", 0)
                text = seg.get("text", "").strip()
                if text:
                    mins = int(start) // 60
                    secs = int(start) % 60
                    transcript_lines.append(f"[{mins:02d}:{secs:02d}] {text}")
            
            transcript = "\n".join(transcript_lines)
            self.log(f"âœ“ Transcription complete: {len(segments)} segments")
            return transcript
            
        except Exception as e:
            self.log(f"Transcription error: {e}")
            return ""
    
    def analyze_and_decide(self, video_info, transcript):
        """AI analyzes video and makes all decisions"""
        self.log("ðŸ¤– AI analyzing and making decisions...")
        
        duration = video_info["duration"]
        width, height = video_info["width"], video_info["height"]
        
        # AI Logic for decisions
        decisions = {}
        
        # 1. Decide number of clips
        if duration < 60:
            decisions["num_clips"] = 2
        elif duration < 180:
            decisions["num_clips"] = 3
        elif duration < 300:
            decisions["num_clips"] = 4
        else:
            decisions["num_clips"] = min(5, int(duration / 120))
        
        # 2. Decide creativity based on content length
        # Longer videos get higher creativity (more variety)
        creativity = min(0.9, 0.6 + (duration / 600))
        decisions["creativity"] = round(creativity, 2)
        
        # 3. Decide clip durations
        target_duration = 15.0  # Target 15 seconds per clip
        total_usable = duration * 0.8  # Use 80% of video
        decisions["target_duration"] = target_duration
        
        # 4. Decide mobile resolution
        if width >= 1920 and height >= 1080:
            decisions["resolution"] = (1080, 1920)  # Full HD mobile
        elif width >= 1280 and height >= 720:
            decisions["resolution"] = (720, 1280)   # HD mobile
        else:
            decisions["resolution"] = (540, 960)    # Standard mobile
        
        # 5. AI selects clips using GPT
        ai_clips = self.ai_select_clips(transcript, duration, decisions)
        decisions["selected_clips"] = ai_clips
        
        self.stats["decisions"] = decisions
        
        # Log AI decisions
        self.log(f"âœ“ AI decided: {decisions['num_clips']} clips")
        self.log(f"âœ“ AI creativity: {decisions['creativity']}")
        self.log(f"âœ“ Mobile resolution: {decisions['resolution'][0]}x{decisions['resolution'][1]}")
        
        return decisions
    
    def ai_select_clips(self, transcript, duration, decisions):
        """Use AI to select the best clips"""
        try:
            import openai
            
            openai.api_key = API_KEY
            openai.api_base = API_BASE
            
            # Prepare prompt for AI
            prompt = f"""As a viral content expert, analyze this video transcript and select {decisions['num_clips']} clips.
            
Video duration: {duration:.1f} seconds
Target clip length: {decisions['target_duration']} seconds each

TRANSCRIPT:
{transcript[:4000]}...

Select clips that:
1. Start with a strong hook (first 3 seconds)
2. Have emotional impact or valuable information
3. Tell a complete mini-story
4. Work well as standalone content

Return ONLY JSON in this format:
{{
  "clips": [
    {{
      "start_time": 123.45,
      "end_time": 138.45,
      "title": "Catchy title",
      "reason": "Why this will go viral",
      "emotion": "funny/surprising/informative/emotional"
    }}
  ]
}}

IMPORTANT: Ensure clips don't overlap and stay within video duration."""
            
            response = openai.ChatCompletion.create(
                model=MODEL,
                messages=[
                    {"role": "system", "content": "You are an expert video editor who knows what makes content go viral on TikTok/Instagram Reels/YouTube Shorts."},
                    {"role": "user", "content": prompt}
                ],
                temperature=decisions["creativity"],
                max_tokens=1500
            )
            
            content = response.choices[0].message.content
            
            # Parse JSON response
            try:
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0].strip()
                elif "```" in content:
                    content = content.split("```")[1].split("```")[0].strip()
                
                data = json.loads(content)
                clips = data.get("clips", [])
                
                # Validate and adjust clips
                validated = []
                for clip in clips[:decisions["num_clips"]]:
                    try:
                        start = float(clip.get("start_time", 0))
                        end = float(clip.get("end_time", start + 15))
                        
                        # Ensure valid times
                        if end <= start:
                            end = start + 15
                        if end - start > 30:  # Max 30 seconds
                            end = start + 25
                        if end > duration:
                            end = duration
                            start = max(0, end - 15)
                        
                        clip["start_time"] = start
                        clip["end_time"] = end
                        clip["duration"] = end - start
                        validated.append(clip)
                    except:
                        continue
                
                self.log(f"âœ“ AI selected {len(validated)} clips")
                return validated
                
            except json.JSONDecodeError:
                self.log("AI response not valid JSON, using fallback")
        
        except Exception as e:
            self.log(f"AI selection failed: {e}")
        
        # Fallback: distribute clips evenly
        return self.fallback_clip_selection(duration, decisions["num_clips"])
    
    def fallback_clip_selection(self, duration, num_clips):
        """Fallback method if AI fails"""
        clips = []
        segment = duration / (num_clips + 1)  # Leave gaps
        
        emotions = ["informative", "engaging", "entertaining", "educational"]
        
        for i in range(num_clips):
            start = segment * i
            end = min(start + 15, duration)
            
            clips.append({
                "start_time": start,
                "end_time": end,
                "title": f"Highlight {i+1}",
                "reason": "Selected by algorithm",
                "emotion": random.choice(emotions),
                "duration": end - start
            })
        
        return clips
    
    def create_shorts(self, decisions):
        """Create the short videos"""
        self.log("Creating mobile-optimized shorts...")
        
        try:
            import moviepy.editor as mp
            
            with mp.VideoFileClip(str(self.video_path)) as source_video:
                for i, clip_data in enumerate(decisions["selected_clips"]):
                    try:
                        start = clip_data["start_time"]
                        end = clip_data["end_time"]
                        
                        # Extract clip
                        subclip = source_video.subclip(start, end)
                        
                        # Convert to mobile format
                        mobile_clip = self.convert_to_mobile(subclip, decisions["resolution"])
                        
                        # Save video
                        filename = f"short_{i+1:02d}_{clip_data.get('emotion', 'viral')}.mp4"
                        output_path = OUTPUT_DIR / filename
                        
                        mobile_clip.write_videofile(
                            str(output_path),
                            codec='libx264',
                            audio_codec='aac',
                            fps=30,
                            preset='fast',
                            audio_bitrate='128k',
                            logger=None
                        )
                        
                        # Save metadata
                        metadata = {
                            "filename": filename,
                            "clip_data": clip_data,
                            "resolution": f"{decisions['resolution'][0]}x{decisions['resolution'][1]}",
                            "created": datetime.now().isoformat()
                        }
                        
                        meta_path = OUTPUT_DIR / f"short_{i+1:02d}_meta.json"
                        with open(meta_path, 'w') as f:
                            json.dump(metadata, f, indent=2)
                        
                        self.stats["results"].append({
                            "file": filename,
                            "duration": clip_data["duration"],
                            "emotion": clip_data.get("emotion", "unknown")
                        })
                        
                        self.log(f"âœ“ Created: {filename} ({clip_data['duration']:.1f}s)")
                        
                        # Clean up
                        mobile_clip.close()
                        subclip.close()
                        
                    except Exception as e:
                        self.log(f"Error creating clip {i+1}: {e}")
                        continue
            
            source_video.close()
            
        except Exception as e:
            self.log(f"Error in video processing: {e}")
    
    def convert_to_mobile(self, clip, target_resolution):
        """Convert clip to mobile format (9:16)"""
        target_width, target_height = target_resolution
        
        # Calculate scaling
        scale = target_height / clip.h
        new_width = int(clip.w * scale)
        
        # Resize
        resized = clip.resize(height=target_height)
        
        # Crop or add background
        if new_width > target_width:
            # Crop sides
            x_center = (new_width - target_width) // 2
            return resized.crop(x1=x_center, width=target_width)
        else:
            # Add black bars on sides
            from moviepy.video.VideoClip import ColorClip
            background = ColorClip(
                size=(target_width, target_height),
                color=(0, 0, 0),
                duration=clip.duration
            )
            
            x_pos = (target_width - new_width) // 2
            import moviepy.editor as mp
            return mp.CompositeVideoClip([
                background,
                resized.set_position((x_pos, 0))
            ])
    
    def create_report(self):
        """Create final report"""
        report = {
            "summary": {
                "total_shorts": len(self.stats["results"]),
                "total_duration": sum(r["duration"] for r in self.stats["results"]),
                "ai_creativity": self.stats["decisions"].get("creativity", 0.7),
                "mobile_resolution": f"{self.stats['decisions'].get('resolution', [0,0])[0]}x{self.stats['decisions'].get('resolution', [0,0])[1]}",
                "generated_at": datetime.now().isoformat()
            },
            "shorts": self.stats["results"]
        }
        
        report_path = OUTPUT_DIR / "ai_report.json"
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2)
        
        # Create simple README
        readme = f"""# AI-Generated Shorts

## Summary
- Shorts created: {report['summary']['total_shorts']}
- Mobile resolution: {report['summary']['mobile_resolution']}
- AI creativity: {report['summary']['ai_creativity']}

## Files
"""
        for i, short in enumerate(self.stats["results"], 1):
            readme += f"{i}. {short['file']} ({short['duration']:.1f}s) - {short['emotion']}\n"
        
        readme += "\n## Ready for:
- TikTok (9:16 format)
- Instagram Reels
- YouTube Shorts
- Facebook/Instagram Stories"
        
        with open(OUTPUT_DIR / "README.txt", 'w') as f:
            f.write(readme)
        
        self.log("âœ“ Report created")
    
    def run(self):
        """Main pipeline"""
        self.log("ðŸš€ Starting AI Shorts Generator - Full Auto")
        
        # 1. Download
        if not self.download_video():
            return False
        
        # 2. Get video info
        video_info = self.get_video_info()
        if video_info["duration"] < 10:
            self.log("âœ— Video too short (min 10 seconds)")
            return False
        
        self.log(f"Video: {video_info['duration']:.1f}s, {video_info['width']}x{video_info['height']}")
        
        # 3. Transcribe
        transcript = self.transcribe_video()
        if not transcript:
            self.log("âœ— Could not transcribe video")
            return False
        
        # 4. AI decisions
        decisions = self.analyze_and_decide(video_info, transcript)
        if not decisions.get("selected_clips"):
            self.log("âœ— No clips selected")
            return False
        
        # 5. Create shorts
        self.create_shorts(decisions)
        
        # 6. Report
        self.create_report()
        
        self.log("âœ… Pipeline completed successfully!")
        return True

# ========== MAIN ==========
if __name__ == "__main__":
    generator = AIShortsGenerator()
    success = generator.run()
    
    if success:
        print(f"\nðŸŽ‰ Success! Check the 'shorts' folder for your videos.")
        print(f"ðŸ“Š Report saved: shorts/ai_report.json")
        print(f"ðŸ“± Videos optimized for: TikTok, Instagram Reels, YouTube Shorts")
        sys.exit(0)
    else:
        print("\nâŒ Pipeline failed")
        sys.exit(1)
EOF

      - name: â–¶ï¸ Run AI Generator
        env:
          VIDEO_URL: ${{ github.event.inputs.video_url }}
        run: |
          echo "ðŸš€ Starting AI Shorts Generator..."
          echo "ðŸ“¹ Video URL: ${VIDEO_URL:0:80}..."
          echo ""
          
          python generate_shorts.py
          
          echo ""
          echo "ðŸ“Š RESULTS:"
          echo "=========="
          
          if [ -d "shorts" ]; then
            echo "ðŸ“ Output files:"
            ls -la shorts/
            
            echo ""
            if [ -f "shorts/README.txt" ]; then
              cat shorts/README.txt
            fi
            
            SHORT_COUNT=$(find shorts -name "*.mp4" 2>/dev/null | wc -l)
            echo ""
            echo "âœ… AI created $SHORT_COUNT mobile-ready shorts"
            echo "ðŸ¤– All decisions made automatically by AI"
          else
            echo "âŒ No output generated"
          fi

      - name: ðŸ“¦ Package results
        run: |
          if [ -d "shorts" ] && [ "$(ls -A shorts 2>/dev/null)" ]; then
            TIMESTAMP=$(date +%Y%m%d_%H%M%S)
            ZIP_NAME="ai_shorts_${TIMESTAMP}.zip"
            
            zip -r "${ZIP_NAME}" shorts/
            
            echo "ðŸ“¦ Package created: ${ZIP_NAME}"
            echo "package_name=${ZIP_NAME}" >> $GITHUB_ENV
          else
            echo "No results to package"
            echo "package_name=none" >> $GITHUB_ENV
          fi

      - name: ðŸ“¤ Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ai-shorts-output
          path: |
            shorts/
            *.zip
          retention-days: 7

      - name: ðŸ“ˆ Final stats
        if: always()
        run: |
          echo ""
          echo "ðŸ“ˆ PIPELINE STATISTICS"
          echo "======================"
          echo "Workflow: ${{ github.workflow }}"
          echo "Run ID: ${{ github.run_id }}"
          echo "Timestamp: $(date)"
          
          if [ -d "shorts" ]; then
            SHORTS=$(find shorts -name "*.mp4" 2>/dev/null | wc -l)
            METADATA=$(find shorts -name "*.json" 2>/dev/null | wc -l)
            
            echo ""
            echo "ðŸ“± MOBILE SHORTS: $SHORTS"
            echo "ðŸ“Š METADATA FILES: $METADATA"
            
            if [ $SHORTS -gt 0 ]; then
              echo ""
              echo "ðŸŽ‰ SUCCESS: AI automatically created $SHORTS shorts"
              echo "ðŸŽ¯ Zero configuration needed"
              echo "ðŸ“± Ready for TikTok/Reels/Shorts"
            fi
          fi
          
          echo ""
          echo "ðŸ‘‰ Download artifacts to get your shorts!"
