name: Viral Shorts â€” single-run pipeline

on:
  workflow_dispatch:
    inputs:
      video_url:
        description: 'Direct MP4 URL (will follow redirects)'
        required: true
        default: 'https://api.vidssave.com/api/contentsite_api/media/download_redirect?request=sgRpmKL3iNBpyIDr4IgGHBXJiSxcf0EYQuGexs_6KdEalT5ycrs3ffYBEZXevrdUBcrNn6iDw8MfLNTFhlNy7biCIOWf4sDWWBA_S3Gc0ACg1ZPIBzwNN6iyUU-0-PuEErnV6vklMuUiHCyNARF0XKYdjAEXIFyrKF3ytFZL3SURwBQ6zqTIxoinSGmbNRzuDj7GLLN2-qE4j55wtrmuN0sRuMHC3v3eqf14UHFW6OQMmpQ5sIwzvVB6Y5OhROhLgjaA0g8XRTd1z8-rT37YaXo2Y1N59CFMiBNLYoMKlQY-ogHXajXJ3IPsDSTl679jtoOgZpQQY4lq8X-k8lRdgZ5x16iwKPU9AC5d20FwHAFwPaA6sqqj6Sulox0JtTHVQT3xcaUUJowztbrK3N1wClY_bp0pTnhFn4ntpiJhobshFeQwTW0cvTh7u-DnwrB6zF3N3uAfdG9YkBFZZfMIps_fqAN_JZe1TE8Xy6dOcm1cAkp4CQA-6VSb2h75I3aACfjLy872k1vGM7UyG_aS1MqWJUICirs_GRhll-ZswtvtiONJHwWROte6JB-8vU4YEOzzqQAnMb6vwwKFoFArv6XjRP9hX__3UF6yn8R7YYtp9bMuc53-ovjN9sdZoX02'
      whisper_model:
        description: 'Whisper model: tiny | base | small | medium | large'
        required: false
        default: 'tiny'
      num_shorts:
        description: 'Number of short clips to produce'
        required: false
        default: '6'
      min_duration:
        description: 'Minimum clip duration (seconds)'
        required: false
        default: '6'
      max_duration:
        description: 'Maximum clip duration (seconds)'
        required: false
        default: '30'

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install system packages
        run: |
          sudo apt-get update -y
          sudo apt-get install -y ffmpeg zip curl

      - name: Install Python packages
        run: |
          python -m pip install --upgrade pip setuptools wheel
          # Install dependencies. opencv-python-headless is crucial for server environments
          python -m pip install -q yt-dlp ffmpeg-python scenedetect opencv-python-headless numpy
          # Install whisper from git
          python -m pip install -q git+https://github.com/openai/whisper.git

      - name: Create Python Script
        # Writing the script to a file first avoids YAML indentation errors with Heredocs
        run: |
          cat > process_video.py << 'EOF'
          import os, json, math, subprocess, sys
          from pathlib import Path

          # Setup paths
          tmp_dir = Path("temp_work")
          tmp_dir.mkdir(exist_ok=True)
          video_path = tmp_dir / "video.mp4"
          outdir = Path("output")
          outdir.mkdir(parents=True, exist_ok=True)

          def run_cmd(cmd):
              print(f"Executing: {' '.join(cmd)}")
              p = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
              if p.returncode != 0:
                  print(f"Error: {p.stderr}")
                  return None
              return p.stdout

          def get_duration(path):
              try:
                  out = run_cmd(["ffprobe","-v","error","-show_entries","format=duration","-of","default=noprint_wrappers=1:nokey=1", str(path)])
                  return float(out.strip()) if out else 0.0
              except Exception:
                  return 0.0

          # 1. DOWNLOAD VIDEO
          url = os.environ.get("VIDEO_URL")
          print(f"Downloading video from {url}...")
          # Try curl first
          subprocess.run(["curl", "-L", url, "-o", str(video_path)])
          
          # Validation
          if not video_path.exists() or video_path.stat().st_size < 1000:
              print("Curl failed or file too small. Trying yt-dlp as fallback...")
              subprocess.run(["yt-dlp", url, "-o", str(video_path)])

          if not video_path.exists():
              print("Failed to download video.")
              sys.exit(1)

          duration = get_duration(video_path)
          print(f"Video duration: {duration}s")

          # 2. TRANSCRIBE
          import whisper
          model_name = os.environ.get("WHISPER_MODEL", "tiny")
          print(f"Loading Whisper model: {model_name}")
          model = whisper.load_model(model_name)
          print("Transcribing... (Please wait)")
          result = model.transcribe(str(video_path))
          segments = result.get("segments", [])
          print(f"Transcribed {len(segments)} segments.")

          # 3. SCENE DETECTION
          scenes = []
          print("Running Scene Detection...")
          try:
              from scenedetect import VideoManager, SceneManager
              from scenedetect.detectors import ContentDetector
              
              video_manager = VideoManager([str(video_path)])
              scene_manager = SceneManager()
              scene_manager.add_detector(ContentDetector(threshold=30.0))
              
              video_manager.start()
              scene_manager.detect_scenes(frame_source=video_manager)
              scene_list = scene_manager.get_scene_list()
              video_manager.release()
              
              for idx, (start, end) in enumerate(scene_list):
                  scenes.append({"start": start.get_seconds(), "end": end.get_seconds(), "scene_id": idx})
              print(f"Detected {len(scenes)} scenes.")
          except Exception as e:
              print(f"Scene detection warning (fallback used): {e}")
          
          # Fallback if no scenes detected
          if not scenes:
              scenes = [{"start": 0.0, "end": duration, "scene_id": 0}]

          # 4. SCORING ALGORITHM
          def score_text(text):
              if not text: return 0.0
              txt = text.lower()
              keywords = ["wow", "amazing", "wtf", "omg", "shocking", "funny", "secret", "never", "best", "wait", "look"]
              score = 0.0
              for k in keywords:
                  if k in txt: score += 2.0
              # Prefer sentences with reasonable length (not too short, not too long)
              words = len(txt.split())
              if 3 < words < 20: score += 1.0
              return score

          proposals = []
          min_d = float(os.environ.get("MIN_DURATION", "6"))
          max_d = float(os.environ.get("MAX_DURATION", "30"))

          for seg in segments:
              s0 = seg.get("start", 0.0)
              e0 = seg.get("end", s0 + 5.0)
              txt = seg.get("text", "")
              
              # Calculate potential clip window around this sentence
              clip_dur = max(min_d, e0 - s0)
              if clip_dur > max_d: clip_dur = max_d
              
              # Center the clip
              mid = (s0 + e0) / 2
              start_prop = max(0, mid - (clip_dur/2))
              end_prop = min(duration, start_prop + clip_dur)
              
              if end_prop - start_prop < min_d: continue

              base_score = score_text(txt)
              
              # Boost score if it aligns with a scene cut (cinematic cut)
              for sc in scenes:
                  # If segment starts near a scene start
                  if abs(sc["start"] - start_prop) < 1.0:
                      base_score += 1.5
              
              proposals.append({
                  "start": start_prop,
                  "end": end_prop,
                  "score": base_score,
                  "text": txt
              })

          # 5. SELECTION (Non-overlapping)
          proposals.sort(key=lambda x: x["score"], reverse=True)
          selected = []
          target_count = int(os.environ.get("NUM_SHORTS", "6"))

          for p in proposals:
              if len(selected) >= target_count: break
              
              overlap = False
              for s in selected:
                  # Check intersection
                  if not (p["end"] <= s["start"] or p["start"] >= s["end"]):
                      overlap = True
                      break
              
              if not overlap:
                  selected.append(p)

          # Fallback if specific proposals failed, just chop the video
          if len(selected) < 1:
              print("No high score segments found, slicing equally.")
              curr = 0
              while len(selected) < target_count and curr < duration:
                  selected.append({"start": curr, "end": min(duration, curr + 15), "score": 0, "text": "Fallback"})
                  curr += 15

          # 6. EXPORT CLIPS
          clips_dir = outdir / "clips"
          clips_dir.mkdir(parents=True, exist_ok=True)
          final_data = []

          for i, clip in enumerate(selected):
              s, e = clip["start"], clip["end"]
              dur = e - s
              fname = f"short_{i+1:02d}_{int(s)}s.mp4"
              out_path = clips_dir / fname
              
              # Re-encoding ensures compatibility and fixes keyframe cutting issues
              print(f"Exporting clip {i+1}: {s:.1f} to {e:.1f}")
              cmd = [
                  "ffmpeg", "-y", "-ss", str(s), "-i", str(video_path),
                  "-t", str(dur),
                  "-c:v", "libx264", "-c:a", "aac", "-preset", "fast",
                  str(out_path)
              ]
              subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
              
              final_data.append({
                  "filename": fname,
                  "start": s,
                  "end": e,
                  "transcript": clip["text"]
              })

          with open(outdir / "metadata.json", "w") as f:
              json.dump(final_data, f, indent=2)
          
          print("Processing complete.")
          EOF

      - name: Run Pipeline
        env:
          VIDEO_URL: ${{ github.event.inputs.video_url }}
          WHISPER_MODEL: ${{ github.event.inputs.whisper_model }}
          NUM_SHORTS: ${{ github.event.inputs.num_shorts }}
          MIN_DURATION: ${{ github.event.inputs.min_duration }}
          MAX_DURATION: ${{ github.event.inputs.max_duration }}
        run: |
          python process_video.py

      - name: Archive Results
        run: |
          zip -r viral_shorts_output.zip output

      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: viral-shorts-clips
          path: viral_shorts_output.zip
