name: ðŸš€ Grok AI Shorts Generator - Enhanced Auto Intelligence

on:
  workflow_dispatch:
    inputs:
      video_url:
        description: 'URL Video (YouTube/MP4/M3U8)'
        required: true
        default: 'https://api.vidssave.com/api/contentsite_api/media/download_redirect?request=sgRpmKL3iNBpyIDr4IgGHBXJiSxcf0EYQuGexs_6KdEalT5ycrs3ffyBEZXevrdUBcrNn6iDw8MfLNTFhlNy7biCIOWf4sDWWBA_S3Gc0ACg1ZPIBzwNN6iyUU-0-PuEErnV6vklMuUiHCyNARF0XK'

jobs:
  auto-shorts-generator:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: ðŸŽ¬ Initialize Grok AI Pipeline
        run: |
          echo "========================================="
          echo "ðŸ¤– GROK AI SHORTS GENERATOR - ENHANCED AUTO"
          echo "========================================="
          echo "âš¡ Grok AI akan menentukan semuanya secara otomatis"
          echo "ðŸ“¹ Video URL: ${{ github.event.inputs.video_url }}"
          echo "ðŸŽ¯ Mode: FULL AUTO - Grok AI memutuskan semuanya"
          echo "ðŸ“± Output: Mobile-optimized (9:16 aspect ratio)"
          echo "ðŸ”§ Enhancements: Improved error handling, multilingual support"
          echo "========================================="
          date

      - name: ðŸ“¥ Checkout Repository
        uses: actions/checkout@v4

      - name: ðŸ Setup Python Environment
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: âš™ï¸ Install System Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg libsm6 libxext6 libgl1-mesa-glx libglib2.0-0 wget curl unzip sox libsox-fmt-mp3 fonts-dejavu

      - name: ðŸ“¦ Install AI & Video Packages
        run: |
          pip install --upgrade pip wheel setuptools
          pip install openai==1.3.0
          pip install openai-whisper==20231117
          pip install yt-dlp==2023.10.13
          pip install moviepy==1.0.3
          pip install pillow==10.0.0
          pip install numpy==1.24.3
          pip install imageio[ffmpeg]==2.31.1
          pip install librosa==0.10.1
          pip install pydub==0.25.1
          pip install tiktoken==0.5.1
          pip install requests==2.31.0
          pip install fonttools  # Added for better text handling if needed
          echo "âœ… All packages installed"

      - name: ðŸ¤– Create Grok Intelligent AI Pipeline
        run: |
          # Create the Python script with proper escaping
          cat > grok_auto_shorts_ai.py << 'SCRIPT_EOF'
#!/usr/bin/env python3
"""
ðŸš€ GROK AI SHORTS GENERATOR - ENHANCED AUTO INTELLIGENCE
Grok AI menentukan semua parameter secara otomatis dengan peningkatan
"""

import os
import sys
import json
import time
import random
import subprocess
import traceback
from pathlib import Path
from typing import List, Dict, Any, Tuple
from datetime import datetime

# ========== AI CONSTANTS ==========
OPENAI_API_KEY = "Kontolondon"
OPENAI_BASE_URL = "https://tes-coral.vercel.app/v1/"
OPENAI_MODEL = "gpt-4"

# ========== DIRECTORIES ==========
WORKSPACE = Path("workspace")
OUTPUT = Path("output")
WORKSPACE.mkdir(exist_ok=True)
OUTPUT.mkdir(exist_ok=True)

VIDEO_PATH = WORKSPACE / "source_video.mp4"
VIDEO_URL = os.environ.get("INPUT_VIDEO_URL", "")

# ========== LOGGER ==========
class Logger:
    @staticmethod
    def info(msg): print(f"[INFO] {msg}")
    @staticmethod
    def success(msg): print(f"[SUCCESS] {msg}")
    @staticmethod
    def warning(msg): print(f"[WARNING] {msg}")
    @staticmethod
    def error(msg): print(f"[ERROR] {msg}")

# ========== VIDEO ANALYZER ==========
class VideoAnalyzer:
    @staticmethod
    def get_video_info(video_path: Path) -> Dict:
        try:
            import moviepy.editor as mp
            clip = mp.VideoFileClip(str(video_path))
            info = {
                "duration": clip.duration,
                "fps": clip.fps,
                "size": clip.size,
                "width": clip.w,
                "height": clip.h
            }
            clip.close()
            return info
        except Exception as e:
            Logger.warning(f"Video analysis failed: {e}")
            return {"duration": 0, "size": (0, 0)}

# ========== AI PARAMETER DECIDER ==========
class AIParameterDecider:
    @staticmethod
    def decide_parameters(video_info: Dict) -> Dict:
        duration = video_info.get("duration", 0)
        width, height = video_info.get("size", (0, 0))
        
        # Enhanced: More dynamic num_clips
        if duration < 60: num_clips = 1
        elif duration < 120: num_clips = 2
        elif duration < 240: num_clips = 3
        elif duration < 360: num_clips = 4
        else: num_clips = min(6, int(duration / 60))
        
        # Enhanced creativity calculation
        creativity = min(1.0, max(0.5, (duration / 500) * 0.8 + 0.2))
        
        # Enhanced resolution decision
        if width * height > 2000000: resolution = (1080, 1920)
        elif width * height > 1000000: resolution = (720, 1280)
        else: resolution = (540, 960)
        
        return {
            "num_clips": num_clips,
            "creativity": round(creativity, 2),
            "resolution": resolution,
            "target_duration": 20.0,  # Enhanced: Longer target for better stories
            "reasoning": f"Video: {duration:.1f}s, {width}x{height}"
        }

# ========== AI CLIP SELECTOR ==========
class AIClipSelector:
    def __init__(self, creativity: float = 0.7):
        self.api_key = OPENAI_API_KEY
        self.base_url = OPENAI_BASE_URL
        self.model = OPENAI_MODEL
        self.creativity = creativity
    
    def select_clips(self, transcript: str, video_duration: float, num_clips: int) -> List[Dict]:
        Logger.info("Grok AI selecting viral clips...")
        
        prompt = self._create_prompt(transcript, video_duration, num_clips)
        
        try:
            from openai import OpenAI
            client = OpenAI(
                api_key=self.api_key,
                base_url=self.base_url
            )
            
            response = client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are Grok, a viral content expert built by xAI for short videos."},
                    {"role": "user", "content": prompt}
                ],
                temperature=self.creativity,
                max_tokens=2500  # Enhanced: More tokens for better responses
            )
            
            content = response.choices[0].message.content
            return self._parse_response(content, video_duration, num_clips)
            
        except Exception as e:
            Logger.error(f"AI selection failed: {e}")
            return self._fallback_selection(video_duration, num_clips)
    
    def _create_prompt(self, transcript: str, duration: float, num_clips: int) -> str:
        return f"""ANALYZE THIS VIDEO AND SELECT {num_clips} VIRAL CLIPS

VIDEO DURATION: {duration:.1f} seconds
TARGET CLIPS: {num_clips} clips (15-30 seconds each)

TRANSCRIPT:
{transcript[:6000]}  # Enhanced: Longer transcript limit

SELECT CLIPS THAT:
1. Start with a strong hook (within 3 seconds)
2. Have emotional impact (funny/surprising/informative/inspiring)
3. Tell a complete mini-story
4. End with curiosity or satisfaction
5. Optimized for viral potential on social media

RETURN JSON FORMAT:
{{
  "clips": [
    {{
      "start_time": 123.45,
      "end_time": 143.45,
      "title": "Catchy title",
      "emotion": "funny/surprising/informative/inspiring",
      "reason": "Why this will go viral"
    }}
  ]
}}"""

    def _parse_response(self, content: str, video_duration: float, num_clips: int) -> List[Dict]:
        try:
            # Enhanced parsing: More robust JSON extraction
            import re
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
            else:
                json_str = content
            
            data = json.loads(json_str)
            clips = data.get("clips", [])[:num_clips]
            
            # Validate clips
            validated = []
            for clip in clips:
                try:
                    start = float(clip.get("start_time", 0))
                    end = float(clip.get("end_time", start + 20))
                    
                    # Ensure valid duration
                    if end <= start: end = start + 20
                    if end - start > 35: end = start + 30
                    if end > video_duration: end = video_duration
                    if start < 0: start = 0
                    
                    clip["start_time"] = start
                    clip["end_time"] = end
                    clip["duration"] = end - start
                    validated.append(clip)
                except:
                    continue
            
            return validated
        except Exception as e:
            Logger.warning(f"Failed to parse AI response: {e}")
            return []
    
    def _fallback_selection(self, video_duration: float, num_clips: int) -> List[Dict]:
        clips = []
        segment = video_duration / max(1, num_clips)  # Avoid division by zero
        
        for i in range(num_clips):
            start = i * segment
            end = min(start + 20, video_duration)
            if end - start < 10: continue  # Skip too short clips
            clips.append({
                "start_time": start,
                "end_time": end,
                "title": f"Grok Highlight {i+1}",
                "emotion": "informative",
                "reason": "Auto-selected by Grok fallback algorithm",
                "duration": end - start
            })
        
        return clips

# ========== MOBILE VIDEO EDITOR ==========
class MobileVideoEditor:
    @staticmethod
    def create_mobile_short(source_path: Path, clip_data: Dict, output_path: Path, resolution: Tuple[int, int]) -> bool:
        try:
            import moviepy.editor as mp
            
            target_width, target_height = resolution
            
            with mp.VideoFileClip(str(source_path)) as video:
                # Extract clip with error handling
                start = max(0, clip_data["start_time"])
                end = min(clip_data["end_time"], video.duration)
                if end <= start: return False
                subclip = video.subclip(start, end)
                
                # Convert to mobile format (9:16)
                mobile_clip = MobileVideoEditor._convert_to_mobile(subclip, target_width, target_height)
                
                # Enhanced export: Better quality options
                mobile_clip.write_videofile(
                    str(output_path),
                    codec='libx264',
                    audio_codec='aac',
                    fps=30,
                    preset='medium',  # Enhanced: Better compression
                    bitrate='2000k',  # Enhanced: Set bitrate for quality
                    audio_bitrate='160k',
                    threads=8,  # Enhanced: More threads
                    logger=None
                )
                
                mobile_clip.close()
                subclip.close()
            
            return True
        except Exception as e:
            Logger.error(f"Failed to create clip: {e}")
            return False
    
    @staticmethod
    def _convert_to_mobile(clip, target_width: int, target_height: int):
        from moviepy.video.VideoClip import ColorClip
        import moviepy.editor as mp
        
        # Enhanced: Smart resize with aspect ratio preservation
        original_aspect = clip.w / clip.h
        target_aspect = target_width / target_height
        
        if original_aspect > target_aspect:
            # Crop width
            new_width = int(target_height * original_aspect)
            resized = clip.resize(height=target_height)
            x_center = (new_width - target_width) // 2
            cropped = resized.crop(x1=x_center, width=target_width)
            return cropped
        else:
            # Add black bars
            new_height = target_height
            new_width = int(new_height * original_aspect)
            resized = clip.resize(width=new_width)
            background = ColorClip(
                size=(target_width, target_height),
                color=(0, 0, 0),
                duration=clip.duration
            )
            x_pos = (target_width - new_width) // 2
            return mp.CompositeVideoClip([background, resized.set_position((x_pos, 0))])

# ========== MAIN PIPELINE ==========
class GrokAutoShortsPipeline:
    def __init__(self):
        self.video_path = VIDEO_PATH
    
    def run(self):
        Logger.info("ðŸš€ Starting Grok Auto AI Pipeline")
        
        try:
            # 1. Download video with enhanced retries
            if not self._download_video():
                return False
            
            # 2. Analyze video
            analyzer = VideoAnalyzer()
            video_info = analyzer.get_video_info(self.video_path)
            
            if video_info["duration"] < 15:  # Enhanced: Min duration 15s
                Logger.error("Video too short (min 15 seconds)")
                return False
            
            # 3. AI decides parameters
            decider = AIParameterDecider()
            decisions = decider.decide_parameters(video_info)
            
            Logger.info(f"Grok AI Decisions: {decisions['num_clips']} clips, Creativity: {decisions['creativity']}")
            Logger.info(f"Mobile Resolution: {decisions['resolution'][0]}x{decisions['resolution'][1]}")
            
            # 4. Transcribe with multilingual support
            transcript = self._transcribe_video()
            
            # 5. AI selects clips
            selector = AIClipSelector(decisions["creativity"])
            clips = selector.select_clips(transcript, video_info["duration"], decisions["num_clips"])
            
            if not clips:
                Logger.error("No clips selected")
                return False
            
            # 6. Create mobile shorts with parallel processing if possible
            editor = MobileVideoEditor()
            successful_clips = []
            
            for i, clip_data in enumerate(clips):
                output_name = f"grok_short_{i+1:03d}_{clip_data.get('emotion', 'viral')}.mp4"
                output_path = OUTPUT / output_name
                
                if editor.create_mobile_short(self.video_path, clip_data, output_path, decisions["resolution"]):
                    # Save metadata
                    clip_meta = {
                        "filename": output_name,
                        "clip_data": clip_data,
                        "resolution": f"{decisions['resolution'][0]}x{decisions['resolution'][1]}",
                        "mobile_optimized": True,
                        "grok_version": "enhanced"
                    }
                    
                    meta_file = OUTPUT / f"grok_short_{i+1:03d}_meta.json"
                    with open(meta_file, 'w', encoding='utf-8') as f:
                        json.dump(clip_meta, f, indent=2, ensure_ascii=False)
                    
                    successful_clips.append(clip_meta)
                    Logger.success(f"Created: {output_name}")
            
            # 7. Create enhanced report
            if successful_clips:
                self._create_report(video_info, decisions, successful_clips)
                return True
            
            return False
            
        except Exception as e:
            Logger.error(f"Pipeline failed: {e}")
            traceback.print_exc()
            return False
    
    def _download_video(self):
        Logger.info("Downloading video...")
        for attempt in range(3):  # Enhanced: Retries
            try:
                # Try yt-dlp first
                cmd = ['yt-dlp', '-f', 'best[height<=1080]', '-o', str(self.video_path), '--quiet', '--no-warnings', VIDEO_URL]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)
                
                if result.returncode == 0 and self.video_path.exists() and self.video_path.stat().st_size > 102400:
                    size_mb = self.video_path.stat().st_size / (1024 * 1024)
                    Logger.success(f"Downloaded: {size_mb:.1f} MB")
                    return True
            except:
                pass
            
            # Fallback to curl
            try:
                cmd = ['curl', '-L', '-o', str(self.video_path), '--max-time', '600', VIDEO_URL]
                subprocess.run(cmd, capture_output=True, timeout=600)
                
                if self.video_path.exists() and self.video_path.stat().st_size > 102400:
                    size_mb = self.video_path.stat().st_size / (1024 * 1024)
                    Logger.success(f"Downloaded via curl: {size_mb:.1f} MB")
                    return True
            except Exception as e:
                Logger.warning(f"Download attempt {attempt+1} failed: {e}")
                time.sleep(5)
        
        Logger.error("All download attempts failed")
        return False
    
    def _transcribe_video(self):
        Logger.info("Transcribing audio with multilingual Whisper...")
        try:
            import whisper
            model = whisper.load_model("medium")  # Multilingual medium as specified
            result = model.transcribe(str(self.video_path), task="transcribe", verbose=False, language=None)  # Enhanced: Auto language detection
            
            # Enhanced format transcript
            transcript_lines = []
            for seg in result.get("segments", [])[:150]:  # Enhanced: More segments
                start = seg.get("start", 0)
                text = seg.get("text", "").strip()
                if text:
                    minutes = int(start) // 60
                    seconds = int(start) % 60
                    transcript_lines.append(f"[{minutes:02d}:{seconds:02d}] {text}")
            
            return "\n".join(transcript_lines)
        except Exception as e:
            Logger.warning(f"Transcription failed: {e}")
            return "Transcription not available"
    
    def _create_report(self, video_info, decisions, clips):
        report = {
            "summary": {
                "total_clips": len(clips),
                "video_duration": video_info["duration"],
                "original_resolution": f"{video_info.get('width', 0)}x{video_info.get('height', 0)}",
                "mobile_resolution": f"{decisions['resolution'][0]}x{decisions['resolution'][1]}",
                "ai_creativity": decisions["creativity"],
                "generated_at": datetime.now().isoformat(),
                "grok_enhancements": "Improved retries, dynamic clips, better quality"
            },
            "clips": [
                {
                    "file": clip["filename"],
                    "emotion": clip["clip_data"].get("emotion", "unknown"),
                    "duration": clip["clip_data"].get("duration", 0),
                    "title": clip["clip_data"].get("title", "")
                }
                for clip in clips
            ]
        }
        
        # Save JSON report
        report_file = OUTPUT / "grok_ai_auto_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # Create README
        readme_file = OUTPUT / "GROK_README.txt"
        with open(readme_file, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("GROK AI SHORTS GENERATOR - ENHANCED AUTO INTELLIGENCE\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"Clips created: {report['summary']['total_clips']}\n")
            f.write(f"Mobile resolution: {report['summary']['mobile_resolution']}\n")
            f.write(f"Video duration: {report['summary']['video_duration']:.1f}s\n\n")
            
            f.write("ðŸ“± Optimized for:\n")
            f.write("- TikTok (9:16 aspect ratio)\n")
            f.write("- Instagram Reels\n")
            f.write("- YouTube Shorts\n")
            f.write("- X Videos\n\n")
            
            f.write("ðŸŽ¯ Grok AI decided everything automatically with enhancements:\n")
            f.write("- Dynamic number of clips\n")
            f.write("- Adaptive creativity level\n")
            f.write("- Smart clip timings\n")
            f.write("- Enhanced mobile resolution\n")
            f.write("- Multilingual transcription\n")
            f.write("- Better error handling\n")

# ========== EXECUTE ==========
if __name__ == "__main__":
    print("=" * 60)
    print("ðŸ¤– GROK AI SHORTS GENERATOR - FULL AUTO MODE")
    print("=" * 60)
    
    pipeline = GrokAutoShortsPipeline()
    success = pipeline.run()
    
    if success:
        print("\n" + "=" * 60)
        print("âœ… GROK PIPELINE COMPLETED SUCCESSFULLY!")
        print("=" * 60)
        print(f"ðŸ“ Output directory: {OUTPUT}")
        sys.exit(0)
    else:
        print("\n" + "=" * 60)
        print("âŒ GROK PIPELINE FAILED!")
        print("=" * 60)
        sys.exit(1)
SCRIPT_EOF

          echo "âœ… Grok AI Pipeline script created"

      - name: â–¶ï¸ Run Grok Auto AI Pipeline
        env:
          INPUT_VIDEO_URL: ${{ github.event.inputs.video_url }}
        run: |
          echo "Starting Grok Auto AI Pipeline..."
          python grok_auto_shorts_ai.py
          
          echo ""
          echo "ðŸ“Š GROK PIPELINE RESULTS:"
          echo "======================"
          
          if [ -d "output" ]; then
            echo "ðŸ“ Output files:"
            ls -la output/
            
            echo ""
            if [ -f "output/GROK_README.txt" ]; then
              echo "ðŸ“‹ GROK AI REPORT:"
              cat output/GROK_README.txt
            fi
            
            MP4_COUNT=$(find output -name "*.mp4" 2>/dev/null | wc -l)
            echo ""
            echo "âœ… SUCCESS: Created $MP4_COUNT enhanced mobile-optimized shorts"
            echo "ðŸ¤– All decisions made automatically by Grok AI"
          else
            echo "âŒ No output generated"
          fi

      - name: ðŸ“¦ Package Results
        run: |
          if [ -d "output" ] && [ "$(ls -A output 2>/dev/null)" ]; then
            TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
            ARCHIVE_NAME="grok_mobile_shorts_${TIMESTAMP}"
            
            # Create archive
            tar -czf "${ARCHIVE_NAME}.tar.gz" output/
            
            echo "ðŸ“¦ Archive created: ${ARCHIVE_NAME}.tar.gz"
            echo "archive_name=${ARCHIVE_NAME}.tar.gz" >> $GITHUB_ENV
          else
            echo "âš ï¸ No output to package"
            echo "archive_name=none" >> $GITHUB_ENV
          fi

      - name: ðŸ“¤ Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: grok-ai-mobile-shorts-auto
          path: |
            output/
            *.tar.gz
          retention-days: 7

      - name: ðŸ“Š Final Stats
        if: always()
        run: |
          echo ""
          echo "ðŸ“ˆ GROK FINAL STATISTICS"
          echo "========================"
          echo "Timestamp: $(date)"
          
          if [ -d "output" ]; then
            MP4_FILES=$(find output -name "*.mp4" 2>/dev/null | wc -l)
            echo "Shorts created: $MP4_FILES"
            
            if [ $MP4_FILES -gt 0 ]; then
              echo "âœ… Grok AI successfully created $MP4_FILES enhanced mobile-ready shorts"
              echo "ðŸŽ¯ No user input needed - Grok AI decided everything with improvements"
            fi
          fi
          
          echo ""
          echo "ðŸš€ Download artifacts to get your enhanced shorts!"
