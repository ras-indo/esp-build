name: ðŸš€ AI Shorts Generator - Auto Intelligence

on:
  workflow_dispatch:
    inputs:
      video_url:
        description: 'URL Video (YouTube/MP4/M3U8)'
        required: true
        default: 'https://api.vidssave.com/api/contentsite_api/media/download_redirect?request=sgRpmKL3iNBpyIDr4IgGHBXJiSxcf0EYQuGexs_6KdEalT5ycrs3ffyBEZXevrdUBcrNn6iDw8MfLNTFhlNy7biCIOWf4sDWWBA_S3Gc0ACg1ZPIBzwNN6iyUU-0-PuEErnV6vklMuUiHCyNARF0XK'

jobs:
  auto-shorts-generator:
    runs-on: ubuntu-latest
    timeout-minutes: 25
    
    steps:
      - name: ðŸŽ¬ Initialize Auto AI Pipeline
        run: |
          echo "========================================"
          echo "ðŸ¤– AI SHORTS GENERATOR - AUTO INTELLIGENCE"
          echo "========================================"
          echo "âš¡ AI akan menentukan semuanya secara otomatis"
          echo "ðŸ“¹ Video URL: ${{ github.event.inputs.video_url }}"
          echo "ðŸŽ¯ Mode: FULL AUTO - AI memutuskan semuanya"
          echo "ðŸ“± Output: Mobile-optimized (9:16 aspect ratio)"
          echo "========================================"
          date

      - name: ðŸ“¥ Checkout Repository
        uses: actions/checkout@v4

      - name: ðŸ Setup Python Environment
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: âš™ï¸ Install System Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg libsm6 libxext6 libgl1-mesa-glx libglib2.0-0 wget curl unzip sox libsox-fmt-mp3

      - name: ðŸ“¦ Install AI & Video Packages
        run: |
          pip install --upgrade pip wheel setuptools
          pip install openai==1.3.0
          pip install openai-whisper==20231117
          pip install yt-dlp==2023.10.13
          pip install moviepy==1.0.3
          pip install pillow==10.0.0
          pip install numpy==1.24.3
          pip install imageio[ffmpeg]==2.31.1
          pip install librosa==0.10.1
          pip install pydub==0.25.1
          pip install tiktoken==0.5.1
          pip install requests==2.31.0
          echo "âœ… All packages installed"

      - name: ðŸ¤– Create Intelligent AI Pipeline
        run: |
          # Create the Python script with proper escaping
          cat > auto_shorts_ai.py << "SCRIPT_EOF"
#!/usr/bin/env python3
"""
ðŸš€ AI SHORTS GENERATOR - AUTO INTELLIGENCE
AI menentukan semua parameter secara otomatis
"""

import os
import sys
import json
import time
import random
import subprocess
import traceback
from pathlib import Path
from typing import List, Dict, Any, Tuple
from datetime import datetime

# ========== AI CONSTANTS ==========
OPENAI_API_KEY = "Kontolondon"
OPENAI_BASE_URL = "https://tes-coral.vercel.app/v1/"
OPENAI_MODEL = "gpt-4"

# ========== DIRECTORIES ==========
WORKSPACE = Path("workspace")
OUTPUT = Path("output")
WORKSPACE.mkdir(exist_ok=True)
OUTPUT.mkdir(exist_ok=True)

VIDEO_PATH = WORKSPACE / "source_video.mp4"
VIDEO_URL = os.environ.get("INPUT_VIDEO_URL", "")

# ========== LOGGER ==========
class Logger:
    @staticmethod
    def info(msg): print(f"[INFO] {msg}")
    @staticmethod
    def success(msg): print(f"[SUCCESS] {msg}")
    @staticmethod
    def warning(msg): print(f"[WARNING] {msg}")
    @staticmethod
    def error(msg): print(f"[ERROR] {msg}")

# ========== VIDEO ANALYZER ==========
class VideoAnalyzer:
    @staticmethod
    def get_video_info(video_path: Path) -> Dict:
        try:
            import moviepy.editor as mp
            clip = mp.VideoFileClip(str(video_path))
            info = {
                "duration": clip.duration,
                "fps": clip.fps,
                "size": clip.size,
                "width": clip.w,
                "height": clip.h
            }
            clip.close()
            return info
        except Exception as e:
            Logger.warning(f"Video analysis failed: {e}")
            return {"duration": 0, "size": (0, 0)}

# ========== AI PARAMETER DECIDER ==========
class AIParameterDecider:
    @staticmethod
    def decide_parameters(video_info: Dict) -> Dict:
        duration = video_info.get("duration", 0)
        width, height = video_info.get("size", (0, 0))
        
        # Determine optimal number of clips
        if duration < 60: num_clips = 2
        elif duration < 180: num_clips = 3
        elif duration < 300: num_clips = 4
        else: num_clips = 5
        
        # Determine creativity based on video length
        creativity = min(0.9, max(0.6, duration / 600))
        
        # Determine mobile resolution
        if width * height > 1000000: resolution = (720, 1280)
        else: resolution = (540, 960)
        
        return {
            "num_clips": num_clips,
            "creativity": round(creativity, 2),
            "resolution": resolution,
            "target_duration": 15.0,
            "reasoning": f"Video: {duration:.1f}s, {width}x{height}"
        }

# ========== AI CLIP SELECTOR ==========
class AIClipSelector:
    def __init__(self, creativity: float = 0.7):
        self.api_key = OPENAI_API_KEY
        self.base_url = OPENAI_BASE_URL
        self.model = OPENAI_MODEL
        self.creativity = creativity
    
    def select_clips(self, transcript: str, video_duration: float, num_clips: int) -> List[Dict]:
        Logger.info("AI selecting viral clips...")
        
        prompt = self._create_prompt(transcript, video_duration, num_clips)
        
        try:
            import openai
            openai.api_key = self.api_key
            openai.api_base = self.base_url
            
            response = openai.ChatCompletion.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are a viral content expert for short videos."},
                    {"role": "user", "content": prompt}
                ],
                temperature=self.creativity,
                max_tokens=2000
            )
            
            content = response.choices[0].message.content
            return self._parse_response(content, video_duration, num_clips)
            
        except Exception as e:
            Logger.error(f"AI selection failed: {e}")
            return self._fallback_selection(video_duration, num_clips)
    
    def _create_prompt(self, transcript: str, duration: float, num_clips: int) -> str:
        return f"""ANALYZE THIS VIDEO AND SELECT {num_clips} VIRAL CLIPS

VIDEO DURATION: {duration:.1f} seconds
TARGET CLIPS: {num_clips} clips (15-25 seconds each)

TRANSCRIPT:
{transcript[:5000]}

SELECT CLIPS THAT:
1. Start with a strong hook (within 3 seconds)
2. Have emotional impact (funny/surprising/informative)
3. Tell a complete mini-story
4. End with curiosity or satisfaction

RETURN JSON FORMAT:
{{
  "clips": [
    {{
      "start_time": 123.45,
      "end_time": 143.45,
      "title": "Catchy title",
      "emotion": "funny/surprising/informative",
      "reason": "Why this will go viral"
    }}
  ]
}}"""

    def _parse_response(self, content: str, video_duration: float, num_clips: int) -> List[Dict]:
        try:
            # Extract JSON
            if "```json" in content:
                json_str = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                json_str = content.split("```")[1].split("```")[0].strip()
            else:
                start = content.find('{')
                end = content.rfind('}') + 1
                json_str = content[start:end]
            
            data = json.loads(json_str)
            clips = data.get("clips", [])[:num_clips]
            
            # Validate clips
            validated = []
            for clip in clips:
                try:
                    start = float(clip.get("start_time", 0))
                    end = float(clip.get("end_time", start + 15))
                    
                    # Ensure valid duration
                    if end <= start: end = start + 15
                    if end - start > 30: end = start + 25
                    if end > video_duration: end = video_duration
                    
                    clip["start_time"] = start
                    clip["end_time"] = end
                    clip["duration"] = end - start
                    validated.append(clip)
                except:
                    continue
            
            return validated
        except Exception as e:
            Logger.warning(f"Failed to parse AI response: {e}")
            return []
    
    def _fallback_selection(self, video_duration: float, num_clips: int) -> List[Dict]:
        clips = []
        segment = video_duration / num_clips
        
        for i in range(num_clips):
            start = i * segment
            end = min(start + 15, video_duration)
            clips.append({
                "start_time": start,
                "end_time": end,
                "title": f"Highlight {i+1}",
                "emotion": "informative",
                "reason": "Auto-selected by fallback algorithm",
                "duration": end - start
            })
        
        return clips

# ========== MOBILE VIDEO EDITOR ==========
class MobileVideoEditor:
    @staticmethod
    def create_mobile_short(source_path: Path, clip_data: Dict, output_path: Path, resolution: Tuple[int, int]) -> bool:
        try:
            import moviepy.editor as mp
            
            target_width, target_height = resolution
            
            with mp.VideoFileClip(str(source_path)) as video:
                # Extract clip
                start = clip_data["start_time"]
                end = clip_data["end_time"]
                subclip = video.subclip(start, end)
                
                # Convert to mobile format (9:16)
                mobile_clip = MobileVideoEditor._convert_to_mobile(subclip, target_width, target_height)
                
                # Export
                mobile_clip.write_videofile(
                    str(output_path),
                    codec='libx264',
                    audio_codec='aac',
                    fps=30,
                    preset='fast',
                    audio_bitrate='128k',
                    threads=4,
                    logger=None
                )
                
                mobile_clip.close()
                subclip.close()
            
            return True
        except Exception as e:
            Logger.error(f"Failed to create clip: {e}")
            return False
    
    @staticmethod
    def _convert_to_mobile(clip, target_width: int, target_height: int):
        from moviepy.video.VideoClip import ColorClip
        import moviepy.editor as mp
        
        # Resize to fit height
        scale = target_height / clip.h
        new_width = int(clip.w * scale)
        resized = clip.resize(width=new_width, height=target_height)
        
        # Crop or add background
        if new_width > target_width:
            x_center = (new_width - target_width) // 2
            cropped = resized.crop(x1=x_center, width=target_width)
            return cropped
        else:
            background = ColorClip(
                size=(target_width, target_height),
                color=(0, 0, 0),
                duration=clip.duration
            )
            x_pos = (target_width - new_width) // 2
            return mp.CompositeVideoClip([background, resized.set_position((x_pos, 0))])

# ========== MAIN PIPELINE ==========
class AutoShortsPipeline:
    def __init__(self):
        self.video_path = VIDEO_PATH
    
    def run(self):
        Logger.info("ðŸš€ Starting Auto AI Pipeline")
        
        try:
            # 1. Download video
            if not self._download_video():
                return False
            
            # 2. Analyze video
            analyzer = VideoAnalyzer()
            video_info = analyzer.get_video_info(self.video_path)
            
            if video_info["duration"] < 10:
                Logger.error("Video too short (min 10 seconds)")
                return False
            
            # 3. AI decides parameters
            decider = AIParameterDecider()
            decisions = decider.decide_parameters(video_info)
            
            Logger.info(f"AI Decisions: {decisions['num_clips']} clips, Creativity: {decisions['creativity']}")
            Logger.info(f"Mobile Resolution: {decisions['resolution'][0]}x{decisions['resolution'][1]}")
            
            # 4. Transcribe
            transcript = self._transcribe_video()
            
            # 5. AI selects clips
            selector = AIClipSelector(decisions["creativity"])
            clips = selector.select_clips(transcript, video_info["duration"], decisions["num_clips"])
            
            if not clips:
                Logger.error("No clips selected")
                return False
            
            # 6. Create mobile shorts
            editor = MobileVideoEditor()
            successful_clips = []
            
            for i, clip_data in enumerate(clips):
                output_name = f"short_{i+1:03d}_{clip_data.get('emotion', 'viral')}.mp4"
                output_path = OUTPUT / output_name
                
                if editor.create_mobile_short(self.video_path, clip_data, output_path, decisions["resolution"]):
                    # Save metadata
                    clip_meta = {
                        "filename": output_name,
                        "clip_data": clip_data,
                        "resolution": f"{decisions['resolution'][0]}x{decisions['resolution'][1]}",
                        "mobile_optimized": True
                    }
                    
                    meta_file = OUTPUT / f"short_{i+1:03d}_meta.json"
                    with open(meta_file, 'w', encoding='utf-8') as f:
                        json.dump(clip_meta, f, indent=2, ensure_ascii=False)
                    
                    successful_clips.append(clip_meta)
                    Logger.success(f"Created: {output_name}")
            
            # 7. Create report
            if successful_clips:
                self._create_report(video_info, decisions, successful_clips)
                return True
            
            return False
            
        except Exception as e:
            Logger.error(f"Pipeline failed: {e}")
            traceback.print_exc()
            return False
    
    def _download_video(self):
        Logger.info("Downloading video...")
        try:
            # Try yt-dlp
            cmd = ['yt-dlp', '-f', 'best[height<=720]', '-o', str(self.video_path), '--quiet', VIDEO_URL]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0 and self.video_path.exists():
                size_mb = self.video_path.stat().st_size / (1024 * 1024)
                Logger.success(f"Downloaded: {size_mb:.1f} MB")
                return True
        except:
            pass
        
        # Fallback to curl
        try:
            cmd = ['curl', '-L', '-o', str(self.video_path), VIDEO_URL]
            subprocess.run(cmd, capture_output=True, timeout=300)
            
            if self.video_path.exists() and self.video_path.stat().st_size > 102400:
                size_mb = self.video_path.stat().st_size / (1024 * 1024)
                Logger.success(f"Downloaded via curl: {size_mb:.1f} MB")
                return True
        except Exception as e:
            Logger.error(f"Download failed: {e}")
        
        return False
    
    def _transcribe_video(self):
        Logger.info("Transcribing audio...")
        try:
            import whisper
            model = whisper.load_model("medium")
            result = model.transcribe(str(self.video_path), task="transcribe", verbose=False)
            
            # Format transcript
            transcript_lines = []
            for seg in result.get("segments", [])[:100]:
                start = seg.get("start", 0)
                text = seg.get("text", "").strip()
                if text:
                    minutes = int(start) // 60
                    seconds = int(start) % 60
                    transcript_lines.append(f"[{minutes:02d}:{seconds:02d}] {text}")
            
            return "\n".join(transcript_lines)
        except Exception as e:
            Logger.warning(f"Transcription failed: {e}")
            return "Transcription not available"
    
    def _create_report(self, video_info, decisions, clips):
        report = {
            "summary": {
                "total_clips": len(clips),
                "video_duration": video_info["duration"],
                "original_resolution": f"{video_info.get('width', 0)}x{video_info.get('height', 0)}",
                "mobile_resolution": f"{decisions['resolution'][0]}x{decisions['resolution'][1]}",
                "ai_creativity": decisions["creativity"],
                "generated_at": datetime.now().isoformat()
            },
            "clips": [
                {
                    "file": clip["filename"],
                    "emotion": clip["clip_data"].get("emotion", "unknown"),
                    "duration": clip["clip_data"].get("duration", 0)
                }
                for clip in clips
            ]
        }
        
        # Save JSON report
        report_file = OUTPUT / "ai_auto_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # Create README
        readme_file = OUTPUT / "README.txt"
        with open(readme_file, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("AI SHORTS GENERATOR - AUTO INTELLIGENCE\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"Clips created: {report['summary']['total_clips']}\n")
            f.write(f"Mobile resolution: {report['summary']['mobile_resolution']}\n")
            f.write(f"Video duration: {report['summary']['video_duration']:.1f}s\n\n")
            
            f.write("ðŸ“± Optimized for:\n")
            f.write("- TikTok (9:16 aspect ratio)\n")
            f.write("- Instagram Reels\n")
            f.write("- YouTube Shorts\n\n")
            
            f.write("ðŸŽ¯ AI decided everything automatically:\n")
            f.write("- Number of clips\n")
            f.write("- Creativity level\n")
            f.write("- Clip timings\n")
            f.write("- Mobile resolution\n")

# ========== EXECUTE ==========
if __name__ == "__main__":
    print("=" * 60)
    print("ðŸ¤– AI SHORTS GENERATOR - FULL AUTO MODE")
    print("=" * 60)
    
    pipeline = AutoShortsPipeline()
    success = pipeline.run()
    
    if success:
        print("\n" + "=" * 60)
        print("âœ… PIPELINE COMPLETED SUCCESSFULLY!")
        print("=" * 60)
        print(f"ðŸ“ Output directory: {OUTPUT}")
        sys.exit(0)
    else:
        print("\n" + "=" * 60)
        print("âŒ PIPELINE FAILED!")
        print("=" * 60)
        sys.exit(1)
SCRIPT_EOF

          echo "âœ… AI Pipeline script created"

      - name: â–¶ï¸ Run Auto AI Pipeline
        env:
          INPUT_VIDEO_URL: ${{ github.event.inputs.video_url }}
        run: |
          echo "Starting Auto AI Pipeline..."
          python auto_shorts_ai.py
          
          echo ""
          echo "ðŸ“Š PIPELINE RESULTS:"
          echo "===================="
          
          if [ -d "output" ]; then
            echo "ðŸ“ Output files:"
            ls -la output/
            
            echo ""
            if [ -f "output/README.txt" ]; then
              echo "ðŸ“‹ AI REPORT:"
              cat output/README.txt
            fi
            
            MP4_COUNT=$(find output -name "*.mp4" 2>/dev/null | wc -l)
            echo ""
            echo "âœ… SUCCESS: Created $MP4_COUNT mobile-optimized shorts"
            echo "ðŸ¤– All decisions made automatically by AI"
          else
            echo "âŒ No output generated"
          fi

      - name: ðŸ“¦ Package Results
        run: |
          if [ -d "output" ] && [ "$(ls -A output 2>/dev/null)" ]; then
            TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
            ARCHIVE_NAME="mobile_shorts_${TIMESTAMP}"
            
            # Create archive
            tar -czf "${ARCHIVE_NAME}.tar.gz" output/
            
            echo "ðŸ“¦ Archive created: ${ARCHIVE_NAME}.tar.gz"
            echo "archive_name=${ARCHIVE_NAME}.tar.gz" >> $GITHUB_ENV
          else
            echo "âš ï¸ No output to package"
            echo "archive_name=none" >> $GITHUB_ENV
          fi

      - name: ðŸ“¤ Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ai-mobile-shorts-auto
          path: |
            output/
            *.tar.gz
          retention-days: 7

      - name: ðŸ“Š Final Stats
        if: always()
        run: |
          echo ""
          echo "ðŸ“ˆ FINAL STATISTICS"
          echo "==================="
          echo "Timestamp: $(date)"
          
          if [ -d "output" ]; then
            MP4_FILES=$(find output -name "*.mp4" 2>/dev/null | wc -l)
            echo "Shorts created: $MP4_FILES"
            
            if [ $MP4_FILES -gt 0 ]; then
              echo "âœ… AI successfully created $MP4_FILES mobile-ready shorts"
              echo "ðŸŽ¯ No user input needed - AI decided everything"
            fi
          fi
          
          echo ""
          echo "ðŸš€ Download artifacts to get your shorts!"
