name: üöÄ AI Shorts Generator - Full Auto

on:
  workflow_dispatch:
    inputs:
      video_url:
        description: 'URL video (YouTube/MP4)'
        required: true
        default: 'https://api.vidssave.com/api/contentsite_api/media/download_redirect?request=sgRpmKL3iNBpyIDr4IgGHBXJiSxcf0EYQuGexs_6KdEalT5ycrs3ffyBEZXevrdUBcrNn6iDw8MfLNTFhlNy7biCIOWf4sDWWBA_S3Gc0ACg1ZPIBzwNN6iyUU-0-PuEErnV6vklMuUiHCyNARF0XK'

jobs:
  generate-shorts:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üêç Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: ‚öôÔ∏è Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg
          
          pip install --upgrade pip
          # Menggunakan moviepy versi <2.0 karena script menggunakan sintaks lama (version 1)
          pip install yt-dlp "moviepy<2.0" openai-whisper
          pip install pillow numpy openai tiktoken

      - name: ü§ñ Create AI script
        run: |
          cat > generate_shorts.py << 'EOF'
          #!/usr/bin/env python3
          """
          AI Shorts Generator - Full Auto
          AI menentukan semuanya: jumlah klip, durasi, kreativitas, dan resolusi
          """

          import os
          import sys
          import json
          import subprocess
          import random
          from pathlib import Path
          from datetime import datetime

          # ========== CONFIG ==========
          # Mengambil API KEY dari Environment Variable (GitHub Secrets) agar aman dan jalan
          API_KEY = os.environ.get("OPENAI_API_KEY", "Kontolondon")
          API_BASE = "https://tes-coral.vercel.app/v1/"
          MODEL = "gpt-4"

          # Setup directories
          BASE_DIR = Path.cwd()
          VIDEO_DIR = BASE_DIR / "videos"
          OUTPUT_DIR = BASE_DIR / "shorts"
          VIDEO_DIR.mkdir(exist_ok=True)
          OUTPUT_DIR.mkdir(exist_ok=True)

          # Get video URL from environment
          VIDEO_URL = os.environ.get("VIDEO_URL", "")

          class AIShortsGenerator:
              def __init__(self):
                  self.video_path = VIDEO_DIR / "source.mp4"
                  self.stats = {
                      "start_time": datetime.now().isoformat(),
                      "decisions": {},
                      "results": []
                  }
              
              def log(self, message):
                  print(f"[{datetime.now().strftime('%H:%M:%S')}] {message}")
              
              def download_video(self):
                  """Download video from URL"""
                  self.log(f"Downloading video from: {VIDEO_URL[:80]}...")
                  
                  # Try yt-dlp first
                  try:
                      cmd = [
                          'yt-dlp', '-f', 'best[height<=720]',
                          '-o', str(self.video_path),
                          '--quiet',
                          VIDEO_URL
                      ]
                      subprocess.run(cmd, check=True, capture_output=True)
                  except:
                      # Fallback to curl
                      self.log("yt-dlp failed, trying curl...")
                      cmd = ['curl', '-L', '-o', str(self.video_path), VIDEO_URL]
                      subprocess.run(cmd, capture_output=True)
                  
                  if self.video_path.exists():
                      size_mb = self.video_path.stat().st_size / (1024 * 1024)
                      self.log(f"‚úì Video downloaded: {size_mb:.1f} MB")
                      return True
                  
                  self.log("‚úó Failed to download video")
                  return False
              
              def get_video_info(self):
                  """Get basic video information"""
                  try:
                      import moviepy.editor as mp
                      with mp.VideoFileClip(str(self.video_path)) as clip:
                          return {
                              "duration": clip.duration,
                              "width": clip.w,
                              "height": clip.h,
                              "fps": clip.fps
                          }
                  except Exception as e:
                      self.log(f"Error getting video info: {e}")
                      return {"duration": 0, "width": 0, "height": 0}
              
              def transcribe_video(self):
                  """Transcribe video using Whisper"""
                  self.log("Transcribing audio with Whisper...")
                  
                  try:
                      import whisper
                      # Gunakan model small/base agar lebih cepat di GitHub Actions (CPU only)
                      model = whisper.load_model("small") 
                      result = model.transcribe(str(self.video_path), verbose=False)
                      
                      # Format transcript for AI
                      segments = result.get("segments", [])
                      transcript_lines = []
                      
                      for seg in segments[:100]:  # First 100 segments max
                          start = seg.get("start", 0)
                          text = seg.get("text", "").strip()
                          if text:
                              mins = int(start) // 60
                              secs = int(start) % 60
                              transcript_lines.append(f"[{mins:02d}:{secs:02d}] {text}")
                      
                      transcript = "\n".join(transcript_lines)
                      self.log(f"‚úì Transcription complete: {len(segments)} segments")
                      return transcript
                      
                  except Exception as e:
                      self.log(f"Transcription error: {e}")
                      return ""
              
              def analyze_and_decide(self, video_info, transcript):
                  """AI analyzes video and makes all decisions"""
                  self.log("ü§ñ AI analyzing and making decisions...")
                  
                  duration = video_info["duration"]
                  width, height = video_info["width"], video_info["height"]
                  
                  # AI Logic for decisions
                  decisions = {}
                  
                  # 1. Decide number of clips
                  if duration < 60:
                      decisions["num_clips"] = 1
                  elif duration < 180:
                      decisions["num_clips"] = 2
                  elif duration < 300:
                      decisions["num_clips"] = 3
                  else:
                      decisions["num_clips"] = min(4, int(duration / 120))
                  
                  # 2. Decide creativity
                  creativity = min(0.9, 0.6 + (duration / 600))
                  decisions["creativity"] = round(creativity, 2)
                  
                  # 3. Decide clip durations
                  decisions["target_duration"] = 15.0
                  
                  # 4. Decide mobile resolution
                  if width >= 1920 and height >= 1080:
                      decisions["resolution"] = (1080, 1920)
                  elif width >= 1280 and height >= 720:
                      decisions["resolution"] = (720, 1280)
                  else:
                      decisions["resolution"] = (540, 960)
                  
                  # 5. AI selects clips using GPT
                  ai_clips = self.ai_select_clips(transcript, duration, decisions)
                  decisions["selected_clips"] = ai_clips
                  
                  self.stats["decisions"] = decisions
                  
                  self.log(f"‚úì AI decided: {decisions['num_clips']} clips")
                  self.log(f"‚úì Resolution: {decisions['resolution'][0]}x{decisions['resolution'][1]}")
                  
                  return decisions
              
              def ai_select_clips(self, transcript, duration, decisions):
                  """Use AI to select the best clips"""
                  try:
                      import openai
                      
                      openai.api_key = API_KEY
                      openai.api_base = API_BASE
                      
                      prompt = f"""As a viral content expert, analyze this video transcript and select {decisions['num_clips']} clips.
                      
          Video duration: {duration:.1f} seconds
          Target clip length: {decisions['target_duration']} seconds each

          TRANSCRIPT:
          {transcript[:3500]}...

          Return ONLY JSON in this format:
          {{
            "clips": [
              {{
                "start_time": 123.45,
                "end_time": 138.45,
                "title": "Title",
                "emotion": "funny"
              }}
            ]
          }}"""
                      
                      response = openai.ChatCompletion.create(
                          model=MODEL,
                          messages=[
                              {"role": "system", "content": "You are a viral content expert."},
                              {"role": "user", "content": prompt}
                          ],
                          temperature=decisions["creativity"]
                      )
                      
                      content = response.choices[0].message.content
                      
                      try:
                          if "```json" in content:
                              content = content.split("```json")[1].split("```")[0].strip()
                          elif "```" in content:
                              content = content.split("```")[1].split("```")[0].strip()
                          
                          data = json.loads(content)
                          clips = data.get("clips", [])
                          
                          validated = []
                          for clip in clips[:decisions["num_clips"]]:
                              try:
                                  start = float(clip.get("start_time", 0))
                                  end = float(clip.get("end_time", start + 15))
                                  
                                  if end <= start: end = start + 15
                                  if end - start > 45: end = start + 45
                                  if end > duration: end = duration
                                  
                                  clip["start_time"] = start
                                  clip["end_time"] = end
                                  clip["duration"] = end - start
                                  validated.append(clip)
                              except:
                                  continue
                          
                          self.log(f"‚úì AI selected {len(validated)} clips")
                          return validated
                          
                      except Exception as e:
                          self.log(f"JSON Parse error: {e}")
                  
                  except Exception as e:
                      self.log(f"AI selection failed: {e}")
                  
                  return self.fallback_clip_selection(duration, decisions["num_clips"])
              
              def fallback_clip_selection(self, duration, num_clips):
                  clips = []
                  segment = duration / (num_clips + 1)
                  for i in range(num_clips):
                      start = segment * i
                      clips.append({
                          "start_time": start,
                          "end_time": start + 15,
                          "title": f"Highlight {i+1}",
                          "emotion": "highlight",
                          "duration": 15
                      })
                  return clips
              
              def create_shorts(self, decisions):
                  self.log("Creating mobile-optimized shorts...")
                  try:
                      import moviepy.editor as mp
                      
                      # Load video once
                      source_video = mp.VideoFileClip(str(self.video_path))
                      
                      for i, clip_data in enumerate(decisions["selected_clips"]):
                          try:
                              start = clip_data["start_time"]
                              end = clip_data["end_time"]
                              
                              subclip = source_video.subclip(start, end)
                              mobile_clip = self.convert_to_mobile(subclip, decisions["resolution"])
                              
                              filename = f"short_{i+1:02d}.mp4"
                              output_path = OUTPUT_DIR / filename
                              
                              mobile_clip.write_videofile(
                                  str(output_path),
                                  codec='libx264',
                                  audio_codec='aac',
                                  fps=24,
                                  preset='ultrafast',
                                  threads=4,
                                  logger=None
                              )
                              
                              self.stats["results"].append({
                                  "file": filename,
                                  "duration": clip_data["duration"]
                              })
                              
                              self.log(f"‚úì Created: {filename}")
                              
                              mobile_clip.close()
                              subclip.close() # Close subclips to free memory
                              
                          except Exception as e:
                              self.log(f"Error creating clip {i+1}: {e}")
                              continue
                              
                      source_video.close()
                      
                  except Exception as e:
                      self.log(f"Error in video processing: {e}")
              
              def convert_to_mobile(self, clip, target_resolution):
                  target_width, target_height = target_resolution
                  
                  # Simple center crop for speed
                  if clip.w / clip.h > target_width / target_height:
                      # Video is wider than target
                      new_h = target_height
                      new_w = int(clip.w * (target_height / clip.h))
                      resized = clip.resize(height=new_h)
                      return resized.crop(x1=(new_w - target_width)//2, width=target_width)
                  else:
                      # Video is taller than target
                      new_w = target_width
                      new_h = int(clip.h * (target_width / clip.w))
                      resized = clip.resize(width=new_w)
                      return resized.crop(y1=(new_h - target_height)//2, height=target_height)
              
              def create_report(self):
                  report_path = OUTPUT_DIR / "ai_report.json"
                  with open(report_path, 'w') as f:
                      json.dump(self.stats, f, indent=2)
                  self.log("‚úì Report created")
              
              def run(self):
                  if not self.download_video(): return False
                  
                  video_info = self.get_video_info()
                  if video_info["duration"] < 10: return False
                  
                  transcript = self.transcribe_video()
                  decisions = self.analyze_and_decide(video_info, transcript)
                  
                  self.create_shorts(decisions)
                  self.create_report()
                  return True

          if __name__ == "__main__":
              generator = AIShortsGenerator()
              if generator.run():
                  sys.exit(0)
              else:
                  sys.exit(1)
          EOF

      - name: ‚ñ∂Ô∏è Run AI Generator
        env:
          VIDEO_URL: ${{ github.event.inputs.video_url }}
          # PASTIKAN ANDA MEMASUKKAN KEY DI GITHUB SECRETS!
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }} 
        run: |
          echo "üöÄ Starting AI Shorts Generator..."
          python generate_shorts.py
          
          echo "üì¶ Listing output:"
          ls -R shorts/ || echo "No shorts dir"

      - name: üì¶ Package results
        if: always()
        run: |
          if [ -d "shorts" ]; then
            zip -r ai_shorts_result.zip shorts/
          fi

      - name: üì§ Upload artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ai-shorts-output
          path: |
            shorts/
            *.zip
          retention-days: 3
