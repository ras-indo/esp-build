name: ðŸ§  Viral Shorts â€” AI Brain (LangChain)

on:
  workflow_dispatch:
    inputs:
      video_url:
        description: 'URL Video MP4'
        required: true
        default: 'https://api.vidssave.com/api/contentsite_api/media/download_redirect?request=sgRpmKL3iNBpyIDr4IgGHBXJiSxcf0EYQuGexs_6KdEalT5ycrs3ffYBEZXevrdUBcrNn6iDw8MfLNTFhlNy7biCIOWf4sDWWBA_S3Gc0ACg1ZPIBzwNN6iyUU-0-PuEErnV6vklMuUiHCyNARF0XKYdjAEXIFyrKF3ytFZL3SURwBQ6zqTIxoinSGmbNRzuDj7GLLN2-qE4j55wtrmuN0sRuMHC3v3eqf14UHFW6OQMmpQ5sIwzvVB6Y5OhROhLgjaA0g8XRTd1z8-rT37YaXo2Y1N59CFMiBNLYoMKlQY-ogHXajXJ3IPsDSTl679jtoOgZpQQY4lq8X-k8lRdgZ5x16iwKPU9AC5d20FwHAFwPaA6sqqj6Sulox0JtTHVQT3xcaUUJowztbrK3N1wClY_bp0pTnhFn4ntpiJhobshFeQwTW0cvTh7u-DnwrB6zF3N3uAfdG9YkBFZZfMIps_fqAN_JZe1TE8Xy6dOcm1cAkp4CQA-6VSb2h75I3aACfjLy872k1vGM7UyG_aS1MqWJUICirs_GRhll-ZswtvtiONJHwWROte6JB-8vU4YEOzzqQAnMb6vwwKFoFArv6XjRP9hX__3UF6yn8R7YYtp9bMuc53-ovjN9sdZoX02'
      openai_api_key:
        description: 'OpenAI API Key (Required for LangChain Brain)'
        required: true
      num_shorts:
        description: 'Jumlah Klip'
        required: false
        default: '5'
      ai_creativity:
        description: 'Temperatur Kreativitas (0.0 - 1.0)'
        required: false
        default: '0.7'

jobs:
  ai-editor-pipeline:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup Python Environment
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install System Libraries
        run: |
          sudo apt-get update -y
          sudo apt-get install -y ffmpeg

      - name: Install AI Dependencies
        run: |
          python -m pip install --upgrade pip
          # LangChain ecosystem & Whisper
          python -m pip install -q yt-dlp ffmpeg-python openai langchain langchain-community langchain-openai tiktoken
          python -m pip install -q git+https://github.com/openai/whisper.git

      - name: Create AI Editor Script
        run: |
          cat > ai_editor.py << 'EOF'
          import os
          import json
          import subprocess
          import sys
          import whisper
          from pathlib import Path
          
          # LangChain Imports
          from langchain_openai import ChatOpenAI
          from langchain.prompts import ChatPromptTemplate
          from langchain.output_parsers import ResponseSchema, StructuredOutputParser

          # === SETUP ===
          VIDEO_URL = os.environ.get("VIDEO_URL")
          OPENAI_KEY = os.environ.get("OPENAI_API_KEY")
          NUM_CLIPS = int(os.environ.get("NUM_SHORTS", 5))
          TEMP = float(os.environ.get("AI_CREATIVITY", 0.7))
          
          WORKDIR = Path("workspace")
          WORKDIR.mkdir(exist_ok=True)
          OUTDIR = Path("output")
          OUTDIR.mkdir(parents=True, exist_ok=True)
          VIDEO_PATH = WORKDIR / "source.mp4"

          if not OPENAI_KEY:
              print("ERROR: OpenAI API Key is missing. LangChain brain cannot work without a model.")
              sys.exit(1)

          # === 1. DOWNLOADER ===
          def download_video():
              print(f"â¬‡ï¸ Downloading video...")
              subprocess.run(["yt-dlp", VIDEO_URL, "-o", str(VIDEO_PATH), "--force-overwrites"], stdout=subprocess.DEVNULL)
              if not VIDEO_PATH.exists():
                  # Fallback curl
                  subprocess.run(["curl", "-L", VIDEO_URL, "-o", str(VIDEO_PATH)])
              
              if VIDEO_PATH.exists():
                  print("âœ… Video downloaded.")
              else:
                  raise Exception("Download failed.")

          # === 2. EARS (Whisper) ===
          def transcribe_video():
              print("ðŸ‘‚ Listening to video (Transcribing)...")
              # Menggunakan model base/small agar cepat, karena kecerdasan ada di GPT nanti
              model = whisper.load_model("base") 
              result = model.transcribe(str(VIDEO_PATH))
              return result["segments"]

          # === 3. BRAIN (LangChain) ===
          def ai_editorial_decision(segments):
              print("ðŸ§  AI Editor is thinking...")
              
              # Format transcript for LLM: [start_time] text
              full_transcript = ""
              for seg in segments:
                  start_fmt = f"{int(seg['start'])}"
                  full_transcript += f"[{start_fmt}s] {seg['text']}\n"

              # Define Output Structure using LangChain Parsers
              # Kita memaksa AI mereturn JSON murni
              response_schemas = [
                  ResponseSchema(name="clips", description="List of objects. Each object has: start_time (int), end_time (int), title (string), viral_reasoning (string), sentiment (string)")
              ]
              output_parser = StructuredOutputParser.from_response_schemas(response_schemas)
              format_instructions = output_parser.get_format_instructions()

              # Initialize Brain (GPT-4o-mini is cheap & smart, or gpt-3.5-turbo)
              llm = ChatOpenAI(
                  temperature=TEMP, 
                  model="gpt-4o-mini", 
                  api_key=OPENAI_KEY
              )

              # The Prompt - NO HARDCODED WORDS HERE
              # Kita memberitahu AI peran dia, bukan kata kunci apa yang harus dicari.
              template_string = """
              You are a genius Video Editor for TikTok and YouTube Shorts.
              Your goal is to extract the top {num_clips} most viral segments from the provided transcript.

              CRITERIA FOR SELECTION (Use your judgment):
              1. **Hook**: The segment must start with something attention-grabbing.
              2. **Coherence**: The segment must make sense on its own.
              3. **Emotion**: Look for humor, shock, useful facts, or strong opinions.
              4. **Duration**: Each clip must be between 15 and 60 seconds.

              Avoid parts that are just housekeeping (like "subscribe now", "intro music", "buffering").

              TRANSCRIPT:
              {transcript}

              {format_instructions}
              """

              prompt = ChatPromptTemplate.from_template(template_string)
              messages = prompt.format_messages(
                  num_clips=NUM_CLIPS,
                  transcript=full_transcript[:15000], # Limit context to avoid token limits
                  format_instructions=format_instructions
              )

              response = llm.invoke(messages)
              print("âœ… AI Decision received.")
              
              try:
                  data = output_parser.parse(response.content)
                  return data["clips"]
              except Exception as e:
                  print(f"âŒ JSON Parsing error: {e}")
                  print("Raw output:", response.content)
                  return []

          # === 4. HANDS (FFMpeg) ===
          def cut_and_package(clips_data):
              print("âœ‚ï¸ Cutting videos based on AI timestamps...")
              
              for idx, clip in enumerate(clips_data):
                  start = float(clip["start_time"])
                  end = float(clip["end_time"])
                  duration = end - start
                  
                  if duration < 5: continue # Skip glitches

                  safe_title = "".join([c for c in clip["title"] if c.isalnum() or c in " -_"]).strip()
                  filename = f"clip_{idx+1:02d}.mp4"
                  out_path = OUTDIR / filename
                  json_path = OUTDIR / f"clip_{idx+1:02d}_meta.json"

                  # Cutting
                  cmd = [
                      "ffmpeg", "-y",
                      "-ss", str(start),
                      "-i", str(VIDEO_PATH),
                      "-t", str(duration),
                      "-c:v", "libx264", "-c:a", "aac", # Re-encode for stability
                      "-preset", "fast",
                      str(out_path)
                  ]
                  subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

                  # Metadata Generation (AI Thoughts)
                  metadata = {
                      "file": filename,
                      "ai_generated_title": clip["title"],
                      "ai_reasoning": clip["viral_reasoning"],
                      "sentiment": clip.get("sentiment", "neutral"),
                      "timestamps": {
                          "start": start,
                          "end": end,
                          "duration": duration
                      },
                      "editor_engine": "LangChain + OpenAI GPT-4o-mini"
                  }
                  
                  with open(json_path, "w") as f:
                      json.dump(metadata, f, indent=2)
                  
                  print(f"ðŸ‘‰ Exported: {filename} | Reason: {clip['viral_reasoning']}")

          # === MAIN EXECUTION ===
          if __name__ == "__main__":
              try:
                  download_video()
                  segments = transcribe_video()
                  
                  # Feed transcript to LangChain
                  selected_clips = ai_editorial_decision(segments)
                  
                  if not selected_clips:
                      print("âš ï¸ AI did not find suitable clips. Exiting.")
                  else:
                      cut_and_package(selected_clips)
                      
              except Exception as e:
                  print(f"âŒ Critical Error: {e}")
                  sys.exit(1)
          EOF

      - name: Run AI Pipeline
        env:
          VIDEO_URL: ${{ github.event.inputs.video_url }}
          OPENAI_API_KEY: ${{ github.event.inputs.openai_api_key }}
          NUM_SHORTS: ${{ github.event.inputs.num_shorts }}
          AI_CREATIVITY: ${{ github.event.inputs.ai_creativity }}
        run: python ai_editor.py

      - name: Archive AI Output
        run: zip -r ai_shorts_pack.zip output

      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: AI-Shorts-Results
          path: ai_shorts_pack.zip
