name: Viral Video Automation

on:
  push:
    branches: [ "main" ]
  workflow_dispatch:

jobs:
  process-video:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg wget
          pip install faster-whisper numpy openai tqdm torch

      - name: Run Video Processing
        shell: python
        env:
          # Masukkan URL Video di sini (Bisa diganti lewat Secrets kalau mau lebih aman)
          VIDEO_URL: "https://api.vidssave.com/api/contentsite_api/media/download_redirect?request=sgRpmKL3iNBpyIDr4IgGHBXJiSxcf0EYQuGexs_6KdEalT5ycrs3ffYBEZXevrdUBcrNn6iDw8MfLNTFhlNy7biCIOWf4sDWWBA_S3Gc0ACg1ZPIBzwNN6iyUU-0-PuEErnV6vklMuUiHCyNARF0XKYdjAEXIFyrKF3ytFZL3SURwBQ6zqTIxoinSGmbNRzuDj7GLLN2-qE4j55wtrmuN0sRuMHC3v3eqf14UHFW6OQMmpQ5sIwzvVB6Y5OhROhLgjaA0g8XRTd1z8-rT37YaXo2Y1N59CFMiBNLYoMKlQY-ogHXajXJ3IPsDSTl679jtoOgZpQQY4lq8X-k8lRdgZ5x16iwKPU9AC5d20FwHAFwPaA6sqqj6Sulox0JtTHVQT3xcaUUJowztbrK3N1wClY_bp0pTnhFn4ntpiJhobshFeQwTW0cvTh7u-DnwrB6zF3N3uAfdG9YkBFZZfMIps_fqAN_JZe1TE8Xy6dOcm1cAkp4CQA-6VSb2h75I3aACfjLy872k1vGM7UyG_aS1MqWJUICirs_GRhll-ZswtvtiONJHwWROte6JB-8vU4YEOzzqQAnMb6vwwKFoFArv6XjRP9hX__3UF6yn8R7YYtp9bMuc53-ovjN9sdZoX02"
          # API Key Hardcoded sesuai request (Sebaiknya pakai Secrets)
          OPENAI_API_KEY: "Kontolondon"
          OPENAI_BASE_URL: "https://tes-coral.vercel.app/v1/"
        run: |
          import os, sys, subprocess, json, re
          from pathlib import Path
          import torch
          from openai import OpenAI

          print("="*60)
          print("DIRECT MEMORY EXECUTION (NO MAIN.PY)")
          print("="*60)

          # --- CONFIG ---
          VIDEO_URL = os.environ.get("VIDEO_URL")
          API_KEY = os.environ.get("OPENAI_API_KEY")
          API_BASE = os.environ.get("OPENAI_BASE_URL")
          
          BASE_DIR = Path.cwd()
          OUTPUT_DIR = BASE_DIR / "output"
          MODELS_DIR = BASE_DIR / "models"
          VIDEO_PATH = BASE_DIR / "video.mp4"
          AUDIO_PATH = BASE_DIR / "audio.wav"
          ZIP_PATH = BASE_DIR / "viral_segments.zip"
          
          OUTPUT_DIR.mkdir(exist_ok=True)
          MODELS_DIR.mkdir(exist_ok=True)

          # --- 1. DOWNLOAD WITH WGET ---
          print(f"\nüì• DOWNLOADING via WGET...")
          try:
              # Pake wget -O video.mp4 "URL"
              cmd = ["wget", "-O", str(VIDEO_PATH), VIDEO_URL]
              subprocess.run(cmd, check=True)
              
              if not VIDEO_PATH.exists() or VIDEO_PATH.stat().st_size < 1000:
                  print("‚ùå Download gagal: File kosong/tidak ada")
                  sys.exit(1)
              print(f"‚úÖ Download OK: {VIDEO_PATH.stat().st_size / (1024*1024):.2f} MB")
          except Exception as e:
              print(f"‚ùå Wget Error: {e}")
              sys.exit(1)

          # --- 2. EXTRACT AUDIO ---
          print("\nüîÑ EXTRACTING AUDIO...")
          subprocess.run([
              "ffmpeg", "-y", "-i", str(VIDEO_PATH), "-vn",
              "-acodec", "pcm_s16le", "-ar", "16000", "-ac", "1",
              str(AUDIO_PATH)
          ], check=True, stderr=subprocess.DEVNULL)

          # --- 3. TRANSCRIBE ---
          print("\nüéôÔ∏è TRANSCRIBING...")
          from faster_whisper import WhisperModel
          model = WhisperModel("medium", device="cpu", compute_type="int8", download_root=str(MODELS_DIR))
          segments, info = model.transcribe(str(AUDIO_PATH), beam_size=5)
          
          transcript_segs = []
          full_text = ""
          for s in segments:
              transcript_segs.append({"start": s.start, "end": s.end, "text": s.text.strip()})
              full_text += s.text + " "
          
          print(f"‚úÖ Transcribed {len(transcript_segs)} segments ({info.duration:.1f}s)")

          # --- 4. GPT ANALYSIS ---
          print("\nüß† GPT-4 ANALYSIS...")
          client = OpenAI(api_key=API_KEY, base_url=API_BASE)
          
          # Context limit biar gak error token
          txt_context = ""
          for s in transcript_segs[:80]: 
              txt_context += f"[{s['start']:.1f}-{s['end']:.1f}] {s['text']}\n"
          
          prompt = """You are a video editor. Task: Extract viral short clips (vertical format).
          RULES:
          1. Return JSON ARRAY ONLY.
          2. Each segment MUST be under 60 seconds.
          3. Timestamps must be pure numbers (e.g. 10.5), DO NOT add 's'.

          Format: [{"start_time": 10.0, "end_time": 30.0, "title": "Topic"}]"""

          try:
              resp = client.chat.completions.create(
                  model="gpt-4",
                  messages=[
                      {"role": "system", "content": prompt},
                      {"role": "user", "content": f"Duration: {info.duration}s\nTranscript:\n{txt_context}"}
                  ],
                  temperature=0.7
              )
              gpt_content = resp.choices[0].message.content.strip()
          except Exception as e:
              print(f"‚ùå GPT Error: {e}")
              sys.exit(1)

          # --- 5. PARSE & CUT ---
          def safe_float(val):
              try: return float(str(val).lower().replace('s', '').strip())
              except: return 0.0

          print("\n‚úÇÔ∏è CUTTING VIDEO...")
          match = re.search(r'\[.*\]', gpt_content, re.DOTALL)
          if match:
              data = json.loads(match.group(0))
              files_created = []
              
              for i, item in enumerate(data, 1):
                  start = safe_float(item.get('start_time', 0))
                  end = safe_float(item.get('end_time', 0))
                  
                  if (end - start) > 60: end = start + 60
                  if (end - start) < 2: continue
                  
                  safe_name = re.sub(r'[^\w\s-]', '', item.get('title', 'clip')).strip().replace(" ", "_")[:30]
                  out_path = OUTPUT_DIR / f"clip_{i}_{safe_name}.mp4"
                  
                  print(f"   Processing: {start}-{end}s -> {out_path.name}")
                  
                  subprocess.run([
                      "ffmpeg", "-y", "-ss", str(start), "-to", str(end),
                      "-i", str(VIDEO_PATH),
                      "-c:v", "libx264", "-c:a", "aac",
                      "-vf", "scale=1080:1920:force_original_aspect_ratio=decrease,pad=1080:1920:(ow-iw)/2:(oh-ih)/2:color=black",
                      str(out_path)
                  ], stderr=subprocess.DEVNULL)
                  
                  if out_path.exists(): files_created.append(out_path)

              # --- 6. ZIP ---
              if files_created:
                  import zipfile
                  print(f"\nüì¶ Zipping {len(files_created)} files...")
                  with zipfile.ZipFile(ZIP_PATH, 'w', zipfile.ZIP_DEFLATED) as zf:
                      for f in files_created: zf.write(f, f.name)
                  print("‚úÖ DONE")
              else:
                  print("‚ö†Ô∏è No valid clips generated.")
          else:
              print("‚ùå No JSON found in GPT response")

      - name: Upload Result
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: viral-video-results
          path: viral_segments.zip
          retention-days: 5
