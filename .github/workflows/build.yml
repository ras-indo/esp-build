name: üé¨ AI Director Ultra (Fixed Whisper Issue)

on:
  workflow_dispatch:
    inputs:
      video_url:
        description: 'URL Video MP4/YouTube'
        required: true
        default: 'https://www.youtube.com/watch?v=dQw4w9WgXcQ'
      num_shorts:
        description: 'Target Jumlah Klip'
        required: false
        default: '3'
      platform:
        description: 'Platform Target'
        required: false
        default: 'tiktok'
        type: choice
        options:
          - tiktok
          - youtube_shorts
          - instagram_reels
          - all
      quality:
        description: 'Kualitas Video'
        required: false
        default: 'balanced'
        type: choice
        options:
          - fast
          - balanced
          - high

jobs:
  ai-director-ultra:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: üìÅ Setup Workspace
        run: |
          mkdir -p workspace output logs
          
      - name: ‚ö° Checkout Repository
        uses: actions/checkout@v4
        
      - name: üêç Setup Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: üîß Install System Dependencies
        run: |
          sudo apt-get update -y
          sudo apt-get install -y \
            ffmpeg \
            libsm6 \
            libxext6 \
            libgl1-mesa-glx \
            git \
            wget \
            curl
          
      - name: üì¶ Install Python Packages (Fixed Whisper)
        run: |
          python -m pip install --upgrade pip
          
          # Install Whisper correctly from GitHub
          pip install git+https://github.com/openai/whisper.git
          
          # Install PyTorch with CPU-only
          pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
          
          # Core AI/ML
          pip install openai==1.12.0
          pip install langchain==0.1.14
          pip install langchain-openai==0.0.8
          
          # Audio/Video Processing
          pip install yt-dlp==2024.4.9
          pip install ffmpeg-python==0.2.0
          pip install pydub==0.25.1
          
          # Utilities
          pip install numpy==1.26.4
          pip install tiktoken==0.6.0
          pip install tqdm==4.66.2
          pip install requests==2.31.0
          pip install colorama==0.4.6
          pip install tenacity==8.2.3
          
      - name: üöÄ Run AI Director Ultra (Simplified)
        env:
          OPENAI_API_KEY: "Kontolondon"
          OPENAI_API_BASE: "https://tes-coral.vercel.app/v1/"
          VIDEO_URL: ${{ github.event.inputs.video_url }}
          NUM_SHORTS: ${{ github.event.inputs.num_shorts || 3 }}
          TARGET_PLATFORM: ${{ github.event.inputs.platform || 'tiktok' }}
          QUALITY_PRESET: ${{ github.event.inputs.quality || 'balanced' }}
        run: |
          cat > ai_director_simple.py << 'EOF'
          import os
          import sys
          import json
          import re
          import subprocess
          import time
          import logging
          from pathlib import Path
          from datetime import datetime
          from typing import List, Dict
          
          import whisper
          import torch
          from tqdm import tqdm
          
          # LangChain imports
          from langchain_openai import ChatOpenAI
          from langchain_core.prompts import ChatPromptTemplate
          from langchain_core.output_parsers import JsonOutputParser
          
          # Setup logging
          logging.basicConfig(
              level=logging.INFO,
              format='%(asctime)s - %(levelname)s - %(message)s'
          )
          logger = logging.getLogger(__name__)
          
          # Configuration
          VIDEO_URL = os.getenv("VIDEO_URL", "")
          NUM_SHORTS = int(os.getenv("NUM_SHORTS", 3))
          OPENAI_API_KEY = "Kontolondon"
          OPENAI_API_BASE = "https://tes-coral.vercel.app/v1/"
          
          WORKDIR = Path("workspace")
          OUTDIR = Path("output")
          WORKDIR.mkdir(exist_ok=True)
          OUTDIR.mkdir(exist_ok=True)
          
          def download_video():
              """Download video using yt-dlp"""
              video_path = WORKDIR / "source_video.mp4"
              
              logger.info(f"üì• Downloading video from: {VIDEO_URL}")
              
              try:
                  import yt_dlp
                  
                  ydl_opts = {
                      'format': 'best[ext=mp4]/best',
                      'outtmpl': str(video_path.with_suffix('.%(ext)s')),
                      'quiet': True,
                      'no_warnings': True,
                      'http_headers': {
                          'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                      }
                  }
                  
                  with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                      info = ydl.extract_info(VIDEO_URL, download=False)
                      if info:
                          logger.info(f"üé¨ Video info: {info.get('title', 'Unknown')}")
                          logger.info(f"   Duration: {info.get('duration', 0)} seconds")
                          
                      ydl.download([VIDEO_URL])
                      
                  # Find downloaded file
                  for ext in ['.mp4', '.mkv', '.webm']:
                      if video_path.with_suffix(ext).exists():
                          actual_file = video_path.with_suffix(ext)
                          if ext != '.mp4':
                              # Convert to mp4
                              subprocess.run([
                                  'ffmpeg', '-i', str(actual_file),
                                  '-c:v', 'copy', '-c:a', 'copy',
                                  str(video_path)
                              ], capture_output=True)
                          else:
                              video_path = actual_file
                          break
                  
                  if video_path.exists() and video_path.stat().st_size > 1024 * 1024:
                      logger.info(f"‚úÖ Downloaded: {video_path.stat().st_size / (1024*1024):.2f} MB")
                      return video_path
                  else:
                      raise ValueError("Download failed or file too small")
                      
              except Exception as e:
                  logger.error(f"‚ùå Download failed: {e}")
                  raise
          
          def transcribe_audio(video_path: Path):
              """Transcribe audio using Whisper"""
              logger.info("üé§ Transcribing audio with Whisper Medium...")
              
              try:
                  # Check device
                  device = "cuda" if torch.cuda.is_available() else "cpu"
                  logger.info(f"Using device: {device}")
                  
                  # Load model
                  model = whisper.load_model("medium")
                  
                  # Transcribe
                  result = model.transcribe(
                      str(video_path),
                      fp16=(device == "cuda"),
                      verbose=False
                  )
                  
                  segments = []
                  for seg in result.get("segments", []):
                      segments.append({
                          'start': float(seg['start']),
                          'end': float(seg['end']),
                          'text': seg['text'].strip(),
                          'duration': float(seg['end'] - seg['start'])
                      })
                  
                  logger.info(f"‚úÖ Transcription complete: {len(segments)} segments")
                  return segments
                  
              except Exception as e:
                  logger.error(f"‚ùå Transcription failed: {e}")
                  raise
          
          def analyze_with_gpt(segments: List[Dict]):
              """Analyze content with GPT-4"""
              logger.info("üß† Analyzing with GPT-4...")
              
              # Prepare transcript
              transcript = ""
              for i, seg in enumerate(segments[:30]):  # Limit to 30 segments
                  start_min = int(seg['start'] // 60)
                  start_sec = int(seg['start'] % 60)
                  transcript += f"[{start_min:02d}:{start_sec:02d}] {seg['text']}\\n"
              
              # Initialize LLM
              llm = ChatOpenAI(
                  model="gpt-4",
                  temperature=0.2,
                  openai_api_key=OPENAI_API_KEY,
                  openai_api_base=OPENAI_API_BASE,
                  timeout=60,
                  max_retries=5
              )
              
              parser = JsonOutputParser()
              
              prompt = ChatPromptTemplate.from_template("""
              Anda adalah AI Director yang ahli dalam konten viral.
              
              Tugas: Pilih {num_clips} klip terbaik dari transkrip video.
              
              TRANSCRIPT:
              {transcript}
              
              INSTRUKSI:
              1. Cari momen dengan emosi kuat
              2. Durasi ideal 8-30 detik
              3. Hindari potongan kata
              4. Berikan judul clickbait
              
              FORMAT OUTPUT (JSON array):
              [
                {{
                  "start_time": 45.2,
                  "end_time": 60.5,
                  "title": "Judul menarik",
                  "viral_score": 85
                }}
              ]
              """)
              
              messages = prompt.format_messages(
                  num_clips=NUM_SHORTS,
                  transcript=transcript[:5000]
              )
              
              try:
                  response = llm.invoke(messages)
                  
                  # Parse JSON
                  content = response.content.strip()
                  json_match = re.search(r'\[.*\]', content, re.DOTALL)
                  if json_match:
                      clips = json.loads(json_match.group())
                  else:
                      clips = json.loads(content)
                  
                  # Validate and add IDs
                  valid_clips = []
                  for i, clip in enumerate(clips):
                      try:
                          start = float(clip['start_time'])
                          end = float(clip['end_time'])
                          if 5 <= (end - start) <= 60:
                              clip['clip_id'] = f"clip_{i+1:03d}"
                              clip['duration'] = end - start
                              valid_clips.append(clip)
                      except (KeyError, ValueError):
                          continue
                  
                  logger.info(f"‚úÖ AI selected {len(valid_clips)} clips")
                  return valid_clips[:NUM_SHORTS]
                  
              except Exception as e:
                  logger.error(f"‚ùå AI analysis failed: {e}")
                  # Generate simple fallback clips
                  return generate_fallback_clips(segments)
          
          def generate_fallback_clips(segments: List[Dict]):
              """Generate simple fallback clips"""
              clips = []
              
              if segments:
                  # Take segments at intervals
                  interval = max(1, len(segments) // NUM_SHORTS)
                  for i in range(min(NUM_SHORTS, len(segments))):
                      idx = i * interval
                      if idx < len(segments):
                          seg = segments[idx]
                          start = seg['start']
                          end = min(start + 15, seg['end'] + 5)
                          
                          clips.append({
                              'clip_id': f"fallback_{i+1:03d}",
                              'start_time': start,
                              'end_time': end,
                              'title': f"Video Highlight {i+1}",
                              'viral_score': 70,
                              'duration': end - start
                          })
              else:
                  # Default clips
                  for i in range(NUM_SHORTS):
                      clips.append({
                          'clip_id': f"default_{i+1:03d}",
                          'start_time': i * 30,
                          'end_time': (i * 30) + 15,
                          'title': f"Content Part {i+1}",
                          'viral_score': 65,
                          'duration': 15
                      })
              
              return clips
          
          def create_video_clips(video_path: Path, clips: List[Dict]):
              """Create video clips from selected segments"""
              logger.info(f"üé¨ Creating {len(clips)} video clips...")
              
              created_count = 0
              for clip in clips:
                  try:
                      output_path = create_single_clip(video_path, clip)
                      if output_path:
                          created_count += 1
                          logger.info(f"‚úÖ Created: {output_path.name}")
                  except Exception as e:
                      logger.error(f"‚ùå Failed to create clip: {e}")
              
              logger.info(f"üéâ Created {created_count}/{len(clips)} clips")
          
          def create_single_clip(video_path: Path, clip: Dict):
              """Create a single video clip"""
              try:
                  # Create safe filename
                  safe_title = re.sub(r'[^\w\s-]', '', clip['title'])
                  safe_title = re.sub(r'[-\s]+', '_', safe_title)
                  safe_title = safe_title[:40]
                  
                  output_filename = f"{safe_title}_{clip['clip_id']}.mp4"
                  output_path = OUTDIR / output_filename
                  
                  start = float(clip['start_time'])
                  duration = float(clip['duration'])
                  
                  # Build FFmpeg command
                  cmd = [
                      'ffmpeg', '-y',
                      '-ss', str(start),
                      '-i', str(video_path),
                      '-t', str(duration),
                      '-c:v', 'libx264',
                      '-preset', 'fast',
                      '-crf', '23',
                      '-c:a', 'aac',
                      '-b:a', '128k',
                      '-movflags', '+faststart',
                      '-vf', 'scale=1080:1920:force_original_aspect_ratio=increase,crop=iw:ih:0:0',
                      str(output_path)
                  ]
                  
                  # Run FFmpeg
                  result = subprocess.run(
                      cmd,
                      capture_output=True,
                      text=True,
                      timeout=120
                  )
                  
                  if result.returncode != 0:
                      logger.error(f"FFmpeg error: {result.stderr[:200]}")
                      return None
                  
                  # Save metadata
                  metadata = {
                      'clip_info': clip,
                      'file_info': {
                          'filename': output_filename,
                          'size_mb': output_path.stat().st_size / (1024*1024),
                          'duration': duration
                      },
                      'generated_at': datetime.now().isoformat()
                  }
                  
                  metadata_path = output_path.with_suffix('.json')
                  with open(metadata_path, 'w', encoding='utf-8') as f:
                      json.dump(metadata, f, indent=2, ensure_ascii=False)
                  
                  return output_path
                  
              except Exception as e:
                  logger.error(f"Clip creation error: {e}")
                  return None
          
          def generate_summary(clips: List[Dict]):
              """Generate summary report"""
              summary_path = OUTDIR / 'summary.json'
              md_path = OUTDIR / 'SUMMARY.md'
              
              summary = {
                  'total_clips': len(clips),
                  'platform': os.getenv("TARGET_PLATFORM", "tiktok"),
                  'quality': os.getenv("QUALITY_PRESET", "balanced"),
                  'generated_at': datetime.now().isoformat(),
                  'clips': clips
              }
              
              with open(summary_path, 'w', encoding='utf-8') as f:
                  json.dump(summary, f, indent=2, ensure_ascii=False)
              
              # Create markdown summary
              with open(md_path, 'w', encoding='utf-8') as f:
                  f.write("# üé¨ AI Director Ultra - Production Summary\n\n")
                  f.write(f"- **Total Clips**: {len(clips)}\n")
                  f.write(f"- **Platform**: {summary['platform']}\n")
                  f.write(f"- **Quality**: {summary['quality']}\n")
                  f.write(f"- **Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                  
                  f.write("## Generated Clips\n")
                  for clip in clips:
                      f.write(f"### {clip['clip_id']}: {clip['title']}\n")
                      f.write(f"- Start: {clip['start_time']:.1f}s\n")
                      f.write(f"- End: {clip['end_time']:.1f}s\n")
                      f.write(f"- Duration: {clip['duration']:.1f}s\n")
                      f.write(f"- Viral Score: {clip.get('viral_score', 'N/A')}/100\n\n")
              
              logger.info("üìä Summary generated")
          
          def main():
              """Main execution"""
              logger.info("üöÄ AI Director Ultra - Starting")
              
              try:
                  # 1. Download
                  video_path = download_video()
                  
                  # 2. Transcribe
                  segments = transcribe_audio(video_path)
                  
                  if not segments:
                      logger.error("‚ùå No segments transcribed")
                      return
                  
                  # 3. AI Analysis
                  clips = analyze_with_gpt(segments)
                  
                  if not clips:
                      logger.error("‚ùå No clips generated")
                      return
                  
                  # 4. Create video clips
                  create_video_clips(video_path, clips)
                  
                  # 5. Generate summary
                  generate_summary(clips)
                  
                  logger.info("üéâ Process completed successfully!")
                  
              except Exception as e:
                  logger.error(f"‚ùå Fatal error: {e}")
                  sys.exit(1)
          
          if __name__ == "__main__":
              main()
          EOF
          
          echo "Running AI Director..."
          python ai_director_simple.py
          
      - name: üì¶ Package Output
        run: |
          echo "üìÅ Output directory:"
          ls -la output/ 2>/dev/null || echo "No output directory"
          
          if [ -d "output" ] && [ "$(ls -A output/ 2>/dev/null)" ]; then
            TIMESTAMP=$(date +%Y%m%d_%H%M%S)
            zip -r "output_$TIMESTAMP.zip" output/
            echo "‚úÖ Output packaged: output_$TIMESTAMP.zip"
          fi
          
      - name: üì§ Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ai-director-output
          path: |
            output/
            output_*.zip
          retention-days: 7
          if-no-files-found: warn
          
      - name: üìä Generate Job Summary
        if: always()
        run: |
          if [ -f "output/SUMMARY.md" ]; then
            cat output/SUMMARY.md >> $GITHUB_STEP_SUMMARY
          else
            echo "## üé¨ AI Director Ultra" >> $GITHUB_STEP_SUMMARY
            echo "Workflow completed." >> $GITHUB_STEP_SUMMARY
            if [ -f "ai_director_simple.py" ]; then
              echo "Script executed." >> $GITHUB_STEP_SUMMARY
            fi
          fi
          
      - name: üßπ Cleanup
        if: always()
        run: |
          rm -rf workspace/ || true
          rm -f ai_director_simple.py || true
