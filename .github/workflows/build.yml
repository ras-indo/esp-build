name: üé¨ AI Director Ultra (Auto-Run + GPT-4 + Whisper Medium)

on:
  workflow_dispatch:
    inputs:
      video_url:
        description: 'URL Video MP4/YouTube'
        required: true
        default: 'https://api.vidssave.com/api/contentsite_api/media/download_redirect?request=sgRpmKL3iNBpyIDr4IgGHBXJiSxcf0EYQuGexs_6KdEalT5ycrs3ffYBEZXevrdUBcrN6iDw8MfLNTFhlNy7biCIOWf4sDWWBA_S3Gc0ACg1ZPIBzwNN6iyUU-0-PuEErnV6vklMuUiHCyNARF0XKYdjAEXIFyrKF3ytFZL3SURwBQ6zqTIxoinSGmbNRzuDj7GLLN2-qE4j55wtrmuN0sRuMHC3v3eqf14UHFW6OQMmpQ5sIwzvVB6Y5OhROhLgjaA0g8XRTd1z8-rT37YaXo2Y1N59CFMiBNLYoMKlQY-ogHXajXJ3IPsDSTl679jtoOgZpQQY4lq8X-k8lRdgZ5x16iwKPU9AC5d20FwHAFwPaA6sqqj6Sulox0JtTHVQT3xcaUUJowztbrK3N1wClY_bp0pTnhFn4ntpiJhobshFeQwTW0cvTh7u-DnwrB6zF3N3uAfdG9YkBFZZfMIps_fqAN_JZe1TE8Xy6dOcm1cAkp4CQA-6VSb2h75I3aACfjLy872k1vGM7UyG_aS1MqWJUICirs_GRhll-ZswtvtiONJHwWROte6JB-8vU4YEOzzqQAnMb6vwwKFoFArv6XjRP9hX__3UF6yn8R7YYtp9bMuc53-ovjN9sdZoX02'
      num_shorts:
        description: 'Target Jumlah Klip'
        required: false
        default: '8'
      platform:
        description: 'Platform Target'
        required: false
        default: 'tiktok'
        type: choice
        options:
          - tiktok
          - youtube_shorts
          - instagram_reels
          - all
      quality:
        description: 'Kualitas Video'
        required: false
        default: 'balanced'
        type: choice
        options:
          - fast
          - balanced
          - high
  push:
    branches: [ main, master ]
    paths:
      - '.github/workflows/ai-director-ultra.yml'
  schedule:
    - cron: '0 6,12,18 * * *'  # Auto-run 3x sehari

jobs:
  ai-director-ultra:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    steps:
      - name: üìÅ Setup Workspace
        run: |
          mkdir -p workspace output logs assets
          
      - name: ‚ö° Checkout Repository
        uses: actions/checkout@v4
        
      - name: üêç Setup Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: üîß Install System Dependencies
        run: |
          sudo apt-get update -y
          sudo apt-get install -y \
            ffmpeg \
            libsm6 \
            libxext6 \
            libgl1-mesa-glx \
            sox \
            libsox-fmt-mp3 \
            imagemagick \
            git \
            wget \
            curl \
            pv
          
      - name: üì¶ Install Python Packages
        run: |
          python -m pip install --upgrade pip
          
          # Core AI/ML
          pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
          pip install openai==1.12.0
          pip install langchain==0.1.14
          pip install langchain-openai==0.0.8
          pip install langchain-community==0.0.24
          
          # Audio/Video Processing
          pip install whisper==1.1.10
          pip install yt-dlp==2024.4.9
          pip install ffmpeg-python==0.2.0
          pip install moviepy==1.0.3
          pip install pydub==0.25.1
          
          # Utilities
          pip install numpy==1.26.4
          pip install pandas==2.2.1
          pip install tiktoken==0.6.0
          pip install tqdm==4.66.2
          pip install pillow==10.2.0
          pip install requests==2.31.0
          pip install colorama==0.4.6
          pip install python-dotenv==1.0.0
          pip install tenacity==8.2.3
          pip install backoff==2.2.1
          
      - name: üöÄ Run AI Director Ultra
        env:
          OPENAI_API_KEY: "Kontolondon"
          OPENAI_API_BASE: "https://tes-coral.vercel.app/v1/"
          VIDEO_URL: ${{ github.event.inputs.video_url }}
          NUM_SHORTS: ${{ github.event.inputs.num_shorts || 8 }}
          TARGET_PLATFORM: ${{ github.event.inputs.platform || 'tiktok' }}
          QUALITY_PRESET: ${{ github.event.inputs.quality || 'balanced' }}
          ENABLE_HARDWARE_ACCEL: true
          MAX_RETRIES: 15
          WORKER_THREADS: 4
        run: |
          # Create AI Director Ultra Python script
          cat > ai_director_ultra.py << 'EOF'
          import os
          import sys
          import json
          import re
          import subprocess
          import gc
          import time
          import asyncio
          import logging
          import hashlib
          import signal
          from pathlib import Path
          from datetime import datetime
          from typing import List, Dict, Any, Optional
          from dataclasses import dataclass
          from concurrent.futures import ThreadPoolExecutor
          
          import torch
          import whisper
          from tqdm import tqdm
          import colorama
          from colorama import Fore, Style
          from tenacity import (
              retry,
              stop_after_attempt,
              wait_exponential,
              retry_if_exception_type
          )
          
          # LangChain imports
          from langchain_openai import ChatOpenAI
          from langchain_core.prompts import ChatPromptTemplate
          from langchain_core.output_parsers import JsonOutputParser
          
          # Initialize colorama
          colorama.init(autoreset=True)
          
          # Configure logging
          logging.basicConfig(
              level=logging.INFO,
              format=f'{Fore.CYAN}%(asctime)s{Style.RESET_ALL} - {Fore.GREEN}%(name)s{Style.RESET_ALL} - {Fore.YELLOW}%(levelname)s{Style.RESET_ALL} - %(message)s',
              handlers=[
                  logging.FileHandler('ai_director.log'),
                  logging.StreamHandler(sys.stdout)
              ]
          )
          logger = logging.getLogger("AI_Director_Ultra")
          
          # ========== CONFIGURATION ==========
          @dataclass
          class Config:
              OPENAI_API_KEY: str = "Kontolondon"
              OPENAI_API_BASE: str = "https://tes-coral.vercel.app/v1/"
              GPT_MODEL: str = "gpt-4"
              WHISPER_MODEL: str = "medium"
              TEMPERATURE: float = 0.2
              MAX_TOKENS: int = 4096
              
              VIDEO_URL: str = os.getenv("VIDEO_URL", "")
              NUM_SHORTS: int = int(os.getenv("NUM_SHORTS", 8))
              TARGET_PLATFORM: str = os.getenv("TARGET_PLATFORM", "tiktok").lower()
              QUALITY_PRESET: str = os.getenv("QUALITY_PRESET", "balanced").lower()
              
              ENABLE_HARDWARE_ACCEL: bool = os.getenv("ENABLE_HARDWARE_ACCEL", "true").lower() == "true"
              WORKER_THREADS: int = int(os.getenv("WORKER_THREADS", 4))
              MAX_RETRIES: int = int(os.getenv("MAX_RETRIES", 15))
              
              WORKDIR: Path = Path("workspace")
              OUTDIR: Path = Path("output")
              LOGDIR: Path = Path("logs")
              ASSETS_DIR: Path = Path("assets")
              
              def __post_init__(self):
                  self.WORKDIR.mkdir(exist_ok=True)
                  self.OUTDIR.mkdir(exist_ok=True)
                  self.LOGDIR.mkdir(exist_ok=True)
                  self.ASSETS_DIR.mkdir(exist_ok=True)
                  
                  if not self.VIDEO_URL:
                      raise ValueError("VIDEO_URL is required!")
          
          config = Config()
          
          # ========== UTILITY FUNCTIONS ==========
          class PerformanceMonitor:
              def __init__(self):
                  self.start_time = time.time()
                  self.stages = {}
                  
              def start_stage(self, stage_name: str):
                  self.stages[stage_name] = {
                      'start': time.time(),
                      'end': None,
                      'duration': None
                  }
                  logger.info(f"{Fore.BLUE}‚ñ∂Ô∏è Starting: {stage_name}{Style.RESET_ALL}")
                  
              def end_stage(self, stage_name: str):
                  if stage_name in self.stages:
                      self.stages[stage_name]['end'] = time.time()
                      duration = self.stages[stage_name]['end'] - self.stages[stage_name]['start']
                      self.stages[stage_name]['duration'] = duration
                      logger.info(f"{Fore.GREEN}‚úÖ Completed: {stage_name} ({duration:.2f}s){Style.RESET_ALL}")
                  
              def get_summary(self):
                  total_time = time.time() - self.start_time
                  return {
                      'total_time': total_time,
                      'stages': self.stages
                  }
          
          # ========== VIDEO DOWNLOADER ==========
          class VideoDownloader:
              @retry(
                  stop=stop_after_attempt(3),
                  wait=wait_exponential(multiplier=1, min=2, max=10)
              )
              def download(self) -> Path:
                  video_path = config.WORKDIR / "source_video.mp4"
                  
                  logger.info(f"{Fore.CYAN}‚¨áÔ∏è Downloading video...{Style.RESET_ALL}")
                  
                  # Try yt-dlp first
                  try:
                      import yt_dlp
                      
                      ydl_opts = {
                          'format': 'best[ext=mp4]/best',
                          'outtmpl': str(video_path.with_suffix('.%(ext)s')),
                          'quiet': True,
                          'no_warnings': True,
                          'http_headers': {
                              'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                          }
                      }
                      
                      with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                          ydl.download([config.VIDEO_URL])
                          
                  except Exception as e:
                      logger.warning(f"yt-dlp failed: {e}, trying curl...")
                      # Fallback to curl
                      subprocess.run([
                          'curl', '-L', config.VIDEO_URL,
                          '-o', str(video_path),
                          '--connect-timeout', '30',
                          '--max-time', '300'
                      ], check=True, capture_output=True)
                  
                  # Verify download
                  if video_path.exists() and video_path.stat().st_size > 1024:
                      logger.info(f"{Fore.GREEN}‚úÖ Download complete: {video_path.stat().st_size / (1024*1024):.2f} MB{Style.RESET_ALL}")
                      return video_path
                  else:
                      raise ValueError("Downloaded file is empty or doesn't exist")
          
          # ========== AUDIO TRANSCRIBER ==========
          class AudioTranscriber:
              def __init__(self):
                  self.device = self._get_device()
                  self.model = None
                  
              def _get_device(self) -> str:
                  if config.ENABLE_HARDWARE_ACCEL and torch.cuda.is_available():
                      gpu_name = torch.cuda.get_device_name(0)
                      logger.info(f"{Fore.MAGENTA}üéÆ GPU Detected: {gpu_name}{Style.RESET_ALL}")
                      return "cuda"
                  else:
                      logger.info(f"{Fore.YELLOW}‚öôÔ∏è Using CPU{Style.RESET_ALL}")
                      return "cpu"
              
              @retry(
                  stop=stop_after_attempt(2),
                  wait=wait_exponential(multiplier=2, min=4, max=20)
              )
              def transcribe(self, video_path: Path) -> List[Dict]:
                  logger.info(f"{Fore.CYAN}üëÇ Loading Whisper Medium model...{Style.RESET_ALL}")
                  
                  try:
                      self.model = whisper.load_model(
                          config.WHISPER_MODEL,
                          device=self.device
                      )
                      
                      logger.info(f"{Fore.CYAN}üîä Transcribing audio...{Style.RESET_ALL}")
                      
                      result = self.model.transcribe(
                          str(video_path),
                          fp16=(self.device == "cuda"),
                          verbose=False,
                          language=None,  # Auto-detect
                          task="transcribe"
                      )
                      
                      segments = result.get("segments", [])
                      
                      # Clean up memory
                      del self.model
                      gc.collect()
                      if self.device == "cuda":
                          torch.cuda.empty_cache()
                      
                      logger.info(f"{Fore.GREEN}‚úÖ Transcription complete: {len(segments)} segments{Style.RESET_ALL}")
                      
                      enhanced_segments = []
                      for seg in segments:
                          enhanced_segments.append({
                              'start': float(seg['start']),
                              'end': float(seg['end']),
                              'text': seg['text'].strip(),
                              'duration': float(seg['end'] - seg['start'])
                          })
                      
                      return enhanced_segments
                      
                  except Exception as e:
                      logger.error(f"{Fore.RED}‚ùå Transcription failed: {e}{Style.RESET_ALL}")
                      raise
          
          # ========== AI DIRECTOR ==========
          class AIDirector:
              def __init__(self):
                  self.llm = None
                  self.parser = JsonOutputParser()
                  
              def _init_llm(self):
                  try:
                      self.llm = ChatOpenAI(
                          model=config.GPT_MODEL,
                          temperature=config.TEMPERATURE,
                          max_tokens=config.MAX_TOKENS,
                          openai_api_key=config.OPENAI_API_KEY,
                          openai_api_base=config.OPENAI_API_BASE,
                          timeout=120,
                          max_retries=10,
                          streaming=False
                      )
                      return True
                  except Exception as e:
                      logger.error(f"{Fore.RED}‚ùå LLM initialization failed: {e}{Style.RESET_ALL}")
                      return False
              
              @retry(
                  stop=stop_after_attempt(config.MAX_RETRIES),
                  wait=wait_exponential(multiplier=2, min=3, max=60),
                  retry=retry_if_exception_type((Exception,))
              )
              def analyze_and_select_clips(self, segments: List[Dict]) -> List[Dict]:
                  logger.info(f"{Fore.CYAN}üß† AI Director analyzing content...{Style.RESET_ALL}")
                  
                  if not self.llm:
                      if not self._init_llm():
                          raise RuntimeError("Failed to initialize LLM")
                  
                  # Prepare transcript
                  transcript = self._prepare_transcript(segments)
                  
                  # Create prompt
                  prompt_template = ChatPromptTemplate.from_template("""
                  ANDA ADALAH AI DIRECTOR untuk konten viral.
                  
                  MISSION: Pilih {num_clips} klip TERBAIK dari video.
                  
                  üìä TRANSCRIPT:
                  {transcript}
                  
                  üéØ KRITERIA:
                  1. HOOK POWER (10 detik pertama menarik)
                  2. EMOTIONAL IMPACT (ada emosi kuat)
                  3. STORY COMPLETENESS (ada awal-tengah-akhir)
                  4. SHAREABILITY (orang ingin membagikan)
                  
                  üìù OUTPUT FORMAT (JSON array):
                  [
                    {
                      "clip_id": "clip_1",
                      "start_time": 45.2,
                      "end_time": 52.8,
                      "duration": 7.6,
                      "title": "Judul Clickbait",
                      "hook_analysis": "Analisis hook...",
                      "emotional_arc": ["curiosity", "surprise"],
                      "viral_score": 92,
                      "viral_reasons": ["emotional", "surprising"],
                      "platform_optimization": {
                        "caption": "Caption menarik...",
                        "hashtags": ["#fyp", "#viral"],
                        "text_overlays": [
                          {"text": "INI GILA!", "time": 0.5, "duration": 2}
                        ]
                      }
                    }
                  ]
                  
                  ‚ö†Ô∏è ATURAN:
                  1. Durasi 5-60 detik
                  2. Hindari potongan kata
                  3. Prioritaskan emosi kuat
                  
                  Pastikan output HANYA JSON.
                  """)
                  
                  messages = prompt_template.format_messages(
                      num_clips=config.NUM_SHORTS,
                      transcript=transcript[:10000]
                  )
                  
                  try:
                      response = self.llm.invoke(messages)
                      
                      # Parse JSON
                      try:
                          clips = json.loads(response.content)
                      except json.JSONDecodeError:
                          json_match = re.search(r'\[.*\]', response.content, re.DOTALL)
                          if json_match:
                              clips = json.loads(json_match.group())
                          else:
                              raise ValueError("No valid JSON found")
                      
                      # Validate clips
                      validated_clips = []
                      for i, clip in enumerate(clips):
                          if self._validate_clip(clip):
                              clip['clip_id'] = f"clip_{i+1:03d}"
                              clip['generated_at'] = datetime.now().isoformat()
                              clip['platform'] = config.TARGET_PLATFORM
                              validated_clips.append(clip)
                      
                      logger.info(f"{Fore.GREEN}‚úÖ AI Director selected {len(validated_clips)} clips{Style.RESET_ALL}")
                      return validated_clips[:config.NUM_SHORTS]
                      
                  except Exception as e:
                      logger.error(f"{Fore.RED}‚ùå AI analysis failed: {e}{Style.RESET_ALL}")
                      raise
              
              def _prepare_transcript(self, segments: List[Dict]) -> str:
                  transcript_lines = []
                  for seg in segments[:150]:
                      start_min = int(seg['start'] // 60)
                      start_sec = int(seg['start'] % 60)
                      text = seg['text'].strip()
                      if text and len(text) > 3:
                          transcript_lines.append(
                              f"[{start_min:02d}:{start_sec:02d}] {text}"
                          )
                  return "\n".join(transcript_lines)
              
              def _validate_clip(self, clip: Dict) -> bool:
                  required_fields = ['start_time', 'end_time', 'title']
                  for field in required_fields:
                      if field not in clip:
                          return False
                  
                  try:
                      start = float(clip['start_time'])
                      end = float(clip['end_time'])
                      if start >= end:
                          return False
                      duration = end - start
                      if duration < 5 or duration > 60:
                          return False
                  except (ValueError, TypeError):
                      return False
                  
                  return True
              
              def generate_fallback_clips(self, segments: List[Dict]) -> List[Dict]:
                  logger.warning(f"{Fore.YELLOW}‚ö†Ô∏è Using fallback clip generation{Style.RESET_ALL}")
                  
                  fallback_clips = []
                  import random
                  
                  if segments:
                      for i in range(min(config.NUM_SHORTS, 5)):
                          seg = segments[i] if i < len(segments) else random.choice(segments)
                          start = seg['start']
                          end = min(start + 15, seg['end'] + 5)
                          
                          fallback_clips.append({
                              'clip_id': f"fallback_{i+1:03d}",
                              'start_time': start,
                              'end_time': end,
                              'duration': end - start,
                              'title': f"Viral Moment {i+1}",
                              'viral_score': 70,
                              'platform_optimization': {
                                  'caption': "Check this out! üëÄ",
                                  'hashtags': ["#viral", "#fyp", "#trending"]
                              }
                          })
                  else:
                      for i in range(min(config.NUM_SHORTS, 3)):
                          fallback_clips.append({
                              'clip_id': f"fallback_{i+1:03d}",
                              'start_time': i * 30,
                              'end_time': (i * 30) + 15,
                              'duration': 15,
                              'title': f"Highlight {i+1}",
                              'viral_score': 60
                          })
                  
                  return fallback_clips
          
          # ========== VIDEO PRODUCER ==========
          class VideoProducer:
              def __init__(self):
                  self.quality_configs = {
                      'fast': {'preset': 'ultrafast', 'crf': '28'},
                      'balanced': {'preset': 'fast', 'crf': '23'},
                      'high': {'preset': 'slow', 'crf': '18'}
                  }
              
              def produce_clips(self, video_path: Path, clips: List[Dict]) -> List[Dict]:
                  logger.info(f"{Fore.CYAN}üé¨ Producing {len(clips)} video clips...{Style.RESET_ALL}")
                  
                  produced_clips = []
                  
                  with ThreadPoolExecutor(max_workers=config.WORKER_THREADS) as executor:
                      futures = []
                      for clip in clips:
                          future = executor.submit(
                              self._produce_single_clip,
                              video_path,
                              clip
                          )
                          futures.append((future, clip))
                      
                      for future, clip in tqdm(futures, desc="Producing clips", unit="clip"):
                          try:
                              result = future.result(timeout=300)
                              if result:
                                  produced_clips.append(result)
                          except Exception as e:
                              logger.error(f"{Fore.RED}‚ùå Failed to produce clip: {e}{Style.RESET_ALL}")
                  
                  return produced_clips
              
              def _produce_single_clip(self, video_path: Path, clip: Dict) -> Optional[Dict]:
                  try:
                      # Generate filename
                      safe_title = self._sanitize_filename(clip.get('title', 'clip'))
                      timestamp = datetime.now().strftime("%H%M%S")
                      output_filename = f"{safe_title[:50]}_{timestamp}.mp4"
                      output_path = config.OUTDIR / output_filename
                      
                      # Get clip parameters
                      start_time = float(clip['start_time'])
                      duration = float(clip.get('duration', clip['end_time'] - clip['start_time']))
                      
                      # Adjust duration
                      if duration > 60:
                          duration = 60
                          clip['end_time'] = start_time + duration
                      
                      # Build FFmpeg command
                      ffmpeg_cmd = self._build_ffmpeg_command(
                          video_path, start_time, duration, output_path
                      )
                      
                      # Execute FFmpeg
                      process = subprocess.run(
                          ffmpeg_cmd,
                          capture_output=True,
                          text=True,
                          timeout=300
                      )
                      
                      if process.returncode != 0:
                          return None
                      
                      # Verify output
                      if not output_path.exists() or output_path.stat().st_size < 1024:
                          return None
                      
                      # Update metadata
                      clip['output_filename'] = output_filename
                      clip['output_path'] = str(output_path)
                      clip['file_size_mb'] = output_path.stat().st_size / (1024 * 1024)
                      
                      # Save metadata
                      metadata_path = output_path.with_suffix('.json')
                      with open(metadata_path, 'w', encoding='utf-8') as f:
                          json.dump(clip, f, indent=2, ensure_ascii=False)
                      
                      return clip
                      
                  except Exception as e:
                      logger.error(f"Clip production failed: {e}")
                      return None
              
              def _build_ffmpeg_command(self, video_path: Path, start: float, 
                                       duration: float, output_path: Path) -> List[str]:
                  config_preset = self.quality_configs.get(config.QUALITY_PRESET, 
                                                         self.quality_configs['balanced'])
                  
                  # Base filters
                  filters = [
                      'scale=1080:1920:force_original_aspect_ratio=increase',
                      'crop=iw:ih:0:0',
                      'fps=30',
                      'format=yuv420p'
                  ]
                  
                  # Add enhancements for balanced/high quality
                  if config.QUALITY_PRESET != 'fast':
                      filters.extend([
                          'eq=brightness=0.05:contrast=1.1:saturation=1.1'
                      ])
                  
                  filter_chain = ','.join(filters)
                  
                  # Build command
                  cmd = [
                      'ffmpeg', '-y',
                      '-ss', str(start),
                      '-i', str(video_path),
                      '-t', str(duration),
                      '-c:v', 'libx264',
                      '-preset', config_preset['preset'],
                      '-crf', config_preset['crf'],
                      '-c:a', 'aac',
                      '-b:a', '128k',
                      '-movflags', '+faststart',
                      '-vf', filter_chain,
                      '-threads', str(config.WORKER_THREADS),
                      str(output_path)
                  ]
                  
                  return cmd
              
              def _sanitize_filename(self, filename: str) -> str:
                  sanitized = re.sub(r'[<>:"/\\|?*]', '', filename)
                  sanitized = re.sub(r'\s+', '_', sanitized)
                  return sanitized.strip('_')[:100]
          
          # ========== REPORT GENERATOR ==========
          class ReportGenerator:
              def generate(self, clips: List[Dict], performance_data: Dict) -> Dict:
                  logger.info(f"{Fore.CYAN}üìä Generating production report...{Style.RESET_ALL}")
                  
                  total_viral_score = sum(c.get('viral_score', 0) for c in clips)
                  avg_viral_score = total_viral_score / max(len(clips), 1)
                  
                  report = {
                      'generation_info': {
                          'timestamp': datetime.now().isoformat(),
                          'platform': config.TARGET_PLATFORM,
                          'num_clips': len(clips),
                          'quality_preset': config.QUALITY_PRESET
                      },
                      'performance': {
                          'total_time': performance_data.get('total_time', 0),
                          'avg_viral_score': round(avg_viral_score, 1)
                      },
                      'clips': [
                          {
                              'clip_id': c.get('clip_id'),
                              'filename': c.get('output_filename'),
                              'duration': c.get('duration'),
                              'viral_score': c.get('viral_score'),
                              'title': c.get('title')
                          }
                          for c in clips
                      ]
                  }
                  
                  # Save report
                  report_path = config.OUTDIR / 'production_report.json'
                  with open(report_path, 'w', encoding='utf-8') as f:
                      json.dump(report, f, indent=2, ensure_ascii=False)
                  
                  # Generate markdown summary
                  summary_path = config.OUTDIR / 'SUMMARY.md'
                  with open(summary_path, 'w', encoding='utf-8') as f:
                      f.write("# üé¨ AI Director Ultra - Production Summary\n\n")
                      f.write(f"- **Platform**: {config.TARGET_PLATFORM}\n")
                      f.write(f"- **Clips Produced**: {len(clips)}\n")
                      f.write(f"- **Average Viral Score**: {avg_viral_score:.1f}/100\n")
                      f.write(f"- **Total Time**: {performance_data['total_time']:.1f}s\n\n")
                      
                      f.write("## Generated Clips\n")
                      f.write("| Clip | Title | Duration | Viral Score |\n")
                      f.write("|------|-------|----------|-------------|\n")
                      
                      for clip in report['clips']:
                          f.write(f"| {clip['clip_id']} | {clip['title'][:30]}... | {clip['duration']:.1f}s | {clip['viral_score']} |\n")
                  
                  logger.info(f"{Fore.GREEN}‚úÖ Report generated{Style.RESET_ALL}")
                  return report
          
          # ========== MAIN EXECUTION ==========
          async def main():
              logger.info(f"{Fore.MAGENTA}üöÄ AI DIRECTOR ULTRA - STARTING{Style.RESET_ALL}")
              
              monitor = PerformanceMonitor()
              
              try:
                  # PHASE 1: DOWNLOAD
                  monitor.start_stage("Download")
                  downloader = VideoDownloader()
                  video_path = downloader.download()
                  monitor.end_stage("Download")
                  
                  # PHASE 2: TRANSCRIPTION
                  monitor.start_stage("Transcription")
                  transcriber = AudioTranscriber()
                  segments = transcriber.transcribe(video_path)
                  monitor.end_stage("Transcription")
                  
                  if not segments:
                      logger.error(f"{Fore.RED}‚ùå No segments transcribed.{Style.RESET_ALL}")
                      sys.exit(1)
                  
                  # PHASE 3: AI ANALYSIS
                  monitor.start_stage("AI Analysis")
                  director = AIDirector()
                  
                  clips = []
                  try:
                      clips = director.analyze_and_select_clips(segments)
                  except Exception as e:
                      logger.error(f"{Fore.RED}‚ùå AI failed, using fallback{Style.RESET_ALL}")
                      clips = director.generate_fallback_clips(segments)
                  
                  monitor.end_stage("AI Analysis")
                  
                  if not clips:
                      logger.error(f"{Fore.RED}‚ùå No clips generated.{Style.RESET_ALL}")
                      sys.exit(1)
                  
                  # PHASE 4: VIDEO PRODUCTION
                  monitor.start_stage("Video Production")
                  producer = VideoProducer()
                  produced_clips = producer.produce_clips(video_path, clips)
                  monitor.end_stage("Video Production")
                  
                  if not produced_clips:
                      logger.error(f"{Fore.RED}‚ùå No clips produced.{Style.RESET_ALL}")
                      sys.exit(1)
                  
                  # PHASE 5: REPORTING
                  monitor.start_stage("Reporting")
                  report_gen = ReportGenerator()
                  performance_data = monitor.get_summary()
                  report = report_gen.generate(produced_clips, performance_data)
                  monitor.end_stage("Reporting")
                  
                  # FINAL SUMMARY
                  logger.info(f"{Fore.GREEN}üéâ PRODUCTION COMPLETE!{Style.RESET_ALL}")
                  logger.info(f"Clips Produced: {len(produced_clips)}")
                  logger.info(f"Output Directory: {config.OUTDIR}")
                  
                  sys.exit(0)
                  
              except KeyboardInterrupt:
                  logger.info(f"{Fore.YELLOW}‚ö†Ô∏è Interrupted{Style.RESET_ALL}")
                  sys.exit(130)
              except Exception as e:
                  logger.error(f"{Fore.RED}‚ùå FATAL ERROR: {e}{Style.RESET_ALL}")
                  sys.exit(1)
          
          if __name__ == "__main__":
              def signal_handler(signum, frame):
                  logger.info(f"{Fore.YELLOW}‚ö†Ô∏è Shutting down...{Style.RESET_ALL}")
                  sys.exit(1)
              
              signal.signal(signal.SIGINT, signal_handler)
              signal.signal(signal.SIGTERM, signal_handler)
              
              asyncio.run(main())
          EOF
          
          # Run the pipeline
          python ai_director_ultra.py
          
      - name: üì¶ Package Output
        run: |
          # Create timestamped archive
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          zip -r "ai_director_output_$TIMESTAMP.zip" output/ workspace/ logs/ 2>/dev/null || true
          
          # List generated files
          echo "üìÅ Generated files:"
          find output/ -type f \( -name "*.mp4" -o -name "*.json" -o -name "*.md" \) 2>/dev/null | sort || true
          
      - name: üì§ Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ai-director-output-${{ github.run_id }}
          path: |
            output/
            logs/
            ai_director_output_*.zip
          retention-days: 30
          if-no-files-found: warn
          
      - name: üìä Upload Summary as Job Summary
        if: always()
        run: |
          if [ -f output/SUMMARY.md ]; then
            cat output/SUMMARY.md >> $GITHUB_STEP_SUMMARY
          else
            echo "## üìä AI Director Ultra" >> $GITHUB_STEP_SUMMARY
            echo "No summary generated." >> $GITHUB_STEP_SUMMARY
          fi
          
      - name: üßπ Cleanup Workspace
        if: always()
        run: |
          # Clean up large files
          rm -rf workspace/ || true
          rm -f ai_director_ultra.py || true
